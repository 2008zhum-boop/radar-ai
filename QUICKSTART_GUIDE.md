# 全网内容库 - 快速开始指南

## 5 分钟快速上手

### 第 1 步：启动后端（2 分钟）

```bash
# 进入后端目录
cd backend

# 启动 FastAPI 服务（使用 Python 虚拟环境）
python main.py

# 或者直接用 uvicorn
uvicorn main:app --reload
```

**预期输出**：
```
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

✅ 后端已启动！

---

### 第 2 步：启动前端（2 分钟）

在新的终端窗口中：

```bash
# 进入前端目录
cd frontend

# 启动开发服务器
npm run dev
```

**预期输出**：
```
VITE v4.0.0  ready in XXX ms

➜  Local:   http://localhost:5173/
```

✅ 前端已启动！

---

### 第 3 步：登录应用（1 分钟）

1. 打开浏览器访问：http://localhost:5173
2. 使用测试账号登录：
   - 用户名：`editor`
   - 密码：`password123`

---

### 第 4 步：进入全网内容库

1. 登录成功后，看到左侧菜单
2. 找到 **知识管理** 分组
3. 点击 **全网内容库** 🌐

---

## 🎯 常见操作

### 操作 1：搜索内容

1. 在搜索框中输入关键词（例如："特斯拉"）
2. 点击 🔍 **检索** 按钮
3. 查看搜索结果

### 操作 2：筛选内容

在"高级筛选器"中选择：
- **时间范围**：近24小时
- **来源平台**：微博、36氪
- **情感属性**：负面
- **处理状态**：未清洗

### 操作 3：预览内容

1. 点击任何内容的标题
2. 弹出框显示完整内容
3. 可点击链接查看原文

### 操作 4：手动关联客户

1. 找到一条未关联的内容（右侧显示"[未关联]"）
2. 点击操作列中的 **🔗** 按钮
3. 选择要关联的客户
4. 点击 **确认关联**

### 操作 5：修正 AI 判定

1. 点击任何内容右侧的 **✏️** 按钮
2. 修改分类（例如："科技/AI"）
3. 修改情感（正面/负面/中性）
4. 点击 **确认修正**

### 操作 6：批量删除

1. 勾选要删除的内容（左侧复选框）
2. 点击上方 **❌ 删除** 按钮
3. 确认删除

### 操作 7：屏蔽信源

1. 勾选某个信源的多条内容
2. 点击上方 **🚫 屏蔽信源** 按钮
3. 填写屏蔽原因
4. 点击 **确认屏蔽**
5. 该信源的所有内容将被自动丢弃

### 操作 8：查看质检统计

在页面顶部的统计卡片中可以看到：
- 今日采集：总采集数
- 垃圾率：垃圾广告的比例
- 正面/负面：情感分布

---

## 📱 界面说明

### 页面布局

```
┌─────────────────────────────────────────┐
│  全网内容库                              │
│  ┌──────────────────────────────────┐  │
│  │ 质检统计: 采集 1250 | 垃圾率 6.8% │  │
│  └──────────────────────────────────┘  │
├─────────────────────────────────────────┤
│ 搜索框 [          ] 🔍                  │
│ ┌─────────────────────────────────────┐ │
│ │ 时间范围:    ▼ 近24小时             │ │
│ │ 来源平台:    ☑微博 ☑36氪 ☑B站      │ │
│ │ 情感属性:    ☑正面 ☑负面 ☑中性     │ │
│ │ 处理状态:    ☑未清洗 ☑已入库       │ │
│ └─────────────────────────────────────┘ │
├─────────────────────────────────────────┤
│ ✓ 已选择 5 条内容                       │
│ [❌ 删除] [🚫 屏蔽信源] [📥 导出]       │
├─────────────────────────────────────────┤
│ ☐  标题           来源    时间  热度   │
│ ☑ ✓ 特斯拉新品..  36氪   10:05  🔥🔥 │
│ ☐   比亚迪销量..  央视   09:30  🔥🔥 │
│ ☑ ✓ ChatGPT 发..  微博   08:45  🔥🔥 │
│ ...                                     │
├─────────────────────────────────────────┤
│ ← 上一页  第 1 / 10 页 (200 条)  下一页 → │
├─────────────────────────────────────────┤
│ 📋 信源黑名单                            │
│ ┌─────────────────────────────────────┐ │
│ │ 贴吧         垃圾广告泛滥  2024-01 │ │
│ │ 某营销号     低质内容      2024-01 │ │
│ └─────────────────────────────────────┘ │
└─────────────────────────────────────────┘
```

### 表格列说明

| 列名 | 说明 |
|------|------|
| ☐ | 复选框，用于批量操作 |
| 标题 | 内容标题，点击可预览 |
| 来源 | 内容来源（微博、36氪等） |
| 时间 | 发布时间（相对时间如"10:05"） |
| 热度 | 热度评分（🔥 越多越热） |
| AI 判定 | AI 自动分析的情感（正面/负面/中性） |
| 关联客户 | 是否已关联客户 |
| 操作 | 🔗 关联 / ✏️ 修正 / ❌ 删除 |

---

## 🔧 常见问题

### Q1: 为什么搜索没有结果？
**A**: 检查以下几点：
- 是否清除了"处理状态"的筛选（默认过滤已废弃的内容）
- 时间范围是否合适（数据可能在"近7天"）
- 关键词是否正确拼写

### Q2: 关联客户后内容在哪里显示？
**A**: 关联后，内容会在：
- 该客户的 **舆情监控** 页面显示
- 客户的 **日报** 中包含该内容

### Q3: 修正 AI 判定后，旧数据会更新吗？
**A**: 是的，修正立即生效。该内容会：
- 标记为"已入库"
- 反映到所有相关的报表和统计中

### Q4: 黑名单中的内容能恢复吗？
**A**: 不能。黑名单操作是：
- 黑名单内的旧内容：标记为"已废弃"
- 黑名单中的新内容：直接不进入系统
- 无法恢复（需要直接修改数据库）

### Q5: 导出的 CSV 文件在哪里？
**A**: 导出的文件会：
- 自动保存到浏览器的"下载"文件夹
- 文件名格式：`content_export_TIMESTAMP.csv`
- 可用 Excel、Numbers 或任何文本编辑器打开

---

## 🚨 故障排除

### 问题：显示"连接失败"

**解决步骤**：
1. 检查后端是否运行：`ps aux | grep main.py`
2. 查看后端有无错误日志
3. 重启后端：`Ctrl+C` 后重新 `python main.py`

### 问题：表格加载很慢

**解决步骤**：
1. 缩小时间范围（只看近24小时）
2. 增加搜索关键词，减少结果数
3. 清除所有筛选条件重新搜索

### 问题：无法修改分类

**解决步骤**：
1. 检查用户权限（必须是 editor 或 admin）
2. 检查浏览器控制台是否有错误（F12）
3. 刷新页面重试

### 问题：黑名单不生效

**解决步骤**：
1. 检查信源名称是否完全匹配
2. 查看数据库中的实际信源名称
3. 从黑名单移除后重新添加

---

## 📞 获取帮助

**常规文档**：查看 `CONTENT_LIBRARY_README.md`
**实现细节**：查看 `IMPLEMENTATION_SUMMARY.md`
**API 文档**：访问 http://localhost:8000/docs（Swagger UI）
**后端日志**：查看后端控制台输出

---

## ⚡ 性能提示

### 搜索优化
- 输入具体关键词比空搜索快
- 减少筛选条件数量
- 使用较小的 page_size（默认 20 已优化）

### 批量操作优化
- 一次最多选择 100 条进行删除
- 如果卡顿，分批操作

### 黑名单优化
- 定期检查黑名单，移除过期的屏蔽
- 屏蔽前确认信源名称完全正确

---

## 🎓 下一步

掌握基本操作后，建议：

1. **了解数据质检**：每天查看统计数据，监控垃圾率
2. **培养编辑习惯**：遇到 AI 误判，及时点击修正
3. **维护黑名单**：定期审查和更新屏蔽的信源
4. **生成报告**：从清洗后的数据生成更准确的舆情报告

---

## 📚 更多资源

- [Full API Documentation](CONTENT_LIBRARY_README.md)
- [Implementation Details](IMPLEMENTATION_SUMMARY.md)
- [Swagger API Explorer](http://localhost:8000/docs)

**祝您使用愉快！** 🎉
