import os
import json
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("DEEPSEEK_API_KEY")
base_url = os.getenv("DEEPSEEK_BASE_URL")

client = None
if api_key:
    client = OpenAI(api_key=api_key, base_url=base_url)

# === ğŸ›¡ï¸ å¼ºåŠ›æ¸…æ´—å‡½æ•° (æœ¬æ¬¡å‡çº§é‡ç‚¹) ===
def extract_json(text):
    """
    ä»ä¹±ä¸ƒå…«ç³Ÿçš„ AI å›å¤ä¸­ï¼Œç²¾å‡†æå–å‡º JSON éƒ¨åˆ†
    """
    if not text: return "{}"
    
    # 1. å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª '{' å’Œæœ€åä¸€ä¸ª '}'
    # re.DOTALL è®© . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦ï¼Œé˜² AI æ¢è¡Œè¾“å‡º
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        return match.group(0)
    
    # 2. å¦‚æœæ²¡æ‰¾åˆ°å¤§æ‹¬å·ï¼Œå°è¯•æ¸…ç† markdown æ ‡è®°åè¿”å›
    text = re.sub(r'```json', '', text)
    text = re.sub(r'```', '', text)
    return text.strip()

# === å…œåº•æ•°æ® ===
def _get_mock_analysis(topic):
    return {
        "topic": topic,
        "emotion": "æ¨¡æ‹Ÿæ•°æ®",
        "strategies": [
            { "title": f"æ·±åº¦è§‚å¯Ÿï¼š{topic}", "angle": "æ·±åº¦è§‚å¯Ÿ", "reason": "å…¨ç½‘çƒ­è®®æ–¹å‘", "icon": "ğŸ‘ï¸" },
            { "title": f"{topic} èƒŒåçš„å•†ä¸šé€»è¾‘", "angle": "å•†ä¸šåˆ†æ", "reason": "é€‚åˆè´¢ç»å—ä¼—", "icon": "ğŸ“Š" },
            { "title": f"ä¸ºä»€ä¹ˆå¤§å®¶éƒ½åœ¨è°ˆè®º {topic}ï¼Ÿ", "angle": "èˆ†è®ºè§£æ„", "reason": "çƒ­ç‚¹å½’å› ", "icon": "ğŸ”¥" }
        ]
    }

def _get_mock_outline(title):
    return [
        {
            "title": f"ã€å¼€ç¯‡ã€‘å¼ºå†²çªå¼•å…¥ï¼š{title}", 
            "sub_points": ["æ ¸å¿ƒå†²çªç‚¹æè¿°", "å½“å‰èˆ†è®ºç°çŠ¶", "æ–‡ç« æ ¸å¿ƒè§‚ç‚¹æŠ›å‡º"]
        },
        {
            "title": "ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘ç°è±¡æ·±åº¦å‰–æ",
            "sub_points": ["æ•°æ®æ”¯æ’‘ï¼ˆMockï¼‰", "å…¸å‹æ¡ˆä¾‹åˆ†æ", "ç”¨æˆ·/å¸‚åœºååº”"]
        },
        {
            "title": "ã€ç¬¬äºŒéƒ¨åˆ†ã€‘æ ¸å¿ƒåŸå› æŒ–æ˜",
            "sub_points": ["è¡¨é¢åŸå› vsæ·±å±‚åŸå› ", "åˆ©ç›Šé“¾æ¡åˆ†æ", "è¡Œä¸šèƒŒæ™¯å½±å“"]
        },
        {
            "title": "ã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘æœªæ¥è¶‹åŠ¿é¢„åˆ¤",
            "sub_points": ["çŸ­æœŸå½±å“é¢„æµ‹", "é•¿æœŸæ ¼å±€æ¼”å˜", "å¯èƒ½çš„å˜æ•°"]
        },
        {
            "title": "ã€ç»“å°¾ã€‘æ€»ç»“ä¸å‡å",
            "sub_points": ["é‡ç”³è§‚ç‚¹", "å¯¹è¯»è€…çš„å»ºè®®/å‘¼å", "é‡‘å¥æ”¶å°¾"]
        }
    ]

# === 1. åˆ†æè¯é¢˜ ===
# === 1. åˆ†æè¯é¢˜ ===
def generate_analysis(topic, hot_context=None):
    if not client: return _get_mock_analysis(topic)
    print(f"ğŸ§  AI åˆ†æä¸­: {topic} (Context: {len(hot_context) if hot_context else 0})")
    
    context_str = ""
    if hot_context and isinstance(hot_context, list):
         context_str = f"\nå½“å‰å…¨ç½‘èˆ†è®ºçƒ­ç‚¹å‚è€ƒï¼š{', '.join(hot_context[:10])}\nè¯·å°è¯•å°†è¯é¢˜ä¸ä¸Šè¿°çƒ­ç‚¹è¿›è¡Œå…³è”å»¶ä¼¸ï¼Œå¯»æ‰¾å…·æœ‰æµé‡æ½œåŠ›çš„åˆ‡å…¥ç‚¹ã€‚"
    
    try:
        import random
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ä¸»ç¼–ã€‚è¯·åˆ†æç”¨æˆ·è¯é¢˜ï¼Œå¹¶ç»“åˆå½“å‰èˆ†è®ºç¯å¢ƒï¼Œç”Ÿæˆ3ä¸ª**å·®å¼‚åŒ–æå¤§**ä¸”æå…·å¸å¼•åŠ›çš„åˆ›ä½œåˆ‡å…¥ç‚¹ï¼ˆStrategiesï¼‰ã€‚
è¦æ±‚ï¼š
1. è¿”å› JSON æ ¼å¼ï¼Œæ ¹å¯¹è±¡åŒ…å«ï¼šemotion (æƒ…ç»ªè¯), strategies (æ•°ç»„)ã€‚
2. strategies æ•°ç»„ä¸­æ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
   - title: æ‹Ÿå®šçš„çˆ†æ¬¾æ ‡é¢˜ï¼ˆå¿…é¡»å¸å¼•çœ¼çƒï¼Œæ‹’ç»å¹³åº¸ï¼‰
   - angle: åˆ‡å…¥ç‚¹åç§°ï¼ˆå¦‚â€œæ·±åº¦è§‚å¯Ÿâ€ã€â€œåç›´è§‰â€ã€â€œèµ„æœ¬åšå¼ˆâ€ã€â€œè¡Œä¸šé»‘å¹•â€ç­‰ï¼Œ**è¯·å‘æŒ¥åˆ›æ„ï¼Œä¸è¦é‡å¤**ï¼‰
   - reason: æ¨èç†ç”±ï¼ˆç»“åˆçƒ­ç‚¹æˆ–è¡Œä¸šè¶‹åŠ¿ï¼‰
   - icon: ä¸€ä¸ªç›¸å…³çš„emojiå›¾æ ‡
3. å¿…é¡»ç»“åˆæä¾›çš„çƒ­ç‚¹ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ï¼‰è¿›è¡Œå‘æ•£ã€‚
4. **æ¯æ¬¡ç”Ÿæˆéƒ½å¿…é¡»å°è¯•å…¨æ–°çš„è§†è§’ï¼Œé¿å…é™ˆè¯æ»¥è°ƒã€‚**"""},
                {"role": "user", "content": f"åˆ†æè¯é¢˜ï¼š{topic}{context_str}\n\n(Random Seed: {random.random()})"}
            ],
            stream=False,
            temperature=0.9
        )
        raw = response.choices[0].message.content
        print(f"ğŸ” [åˆ†æ-åŸå§‹è¿”å›]: {raw[:100]}...") 
        
        clean = extract_json(raw) 
        return json.loads(clean)
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return _get_mock_analysis(topic)

# === 2. ç”Ÿæˆå¤§çº² ===
def generate_outline(title, angle):
    if not client: return _get_mock_outline(title)
    print(f"ğŸ“ AI å†™å¤§çº²: {title}")
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè´¢ç»ç§‘æŠ€åª’ä½“çš„ä¸»ç¼–ã€‚è¯·æ ¹æ®æ ‡é¢˜å’Œç‰¹å®šåˆ‡å…¥ç‚¹ï¼ˆAngleï¼‰ï¼Œè®¾è®¡ä¸€ä»½é€»è¾‘ä¸¥å¯†ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„æ–‡ç« å¤§çº²ã€‚
    
    æ ¸å¿ƒè¦æ±‚ï¼š
    1. **æ‹’ç»æ­»æ¿çš„æ¨¡æ¿**ï¼šä¸¥ç¦ä½¿ç”¨â€œç¬¬ä¸€ç« ã€ç¬¬äºŒç« â€è¿™ç§æ•™ç§‘ä¹¦å¼çš„æ­»æ¿æ ‡é¢˜ã€‚å°æ ‡é¢˜å¿…é¡»å…·æœ‰æ–°é—»æ€§å’Œè§‚ç‚¹æ€§ï¼ˆä¾‹å¦‚ï¼šâ€œæ³¡æ²«ç ´è£‚çš„å‰å¤œâ€ã€â€œå·¨å¤´çš„éšç§˜å¸ƒå±€â€ï¼‰ã€‚
    2. **ä¸ä»…æ˜¯åˆ—ä¸¾**ï¼šå¤§çº²å¿…é¡»ä½“ç°é€»è¾‘é€’è¿›ï¼ˆç°è±¡ -> åŸå›  -> åˆ©ç›Šåšå¼ˆ -> ç»ˆå±€æ¨æ¼”ï¼‰ã€‚
    3. **JSONæ ¼å¼è¿”å›**ï¼šæ ¹èŠ‚ç‚¹ "sections"ï¼ŒåŒ…å« "title" å’Œ "sub_points"ã€‚
    
    ç¤ºä¾‹æ ¼å¼ï¼š
    {
        "sections": [
            { "title": "ã€åˆ‡é¢ã€‘....", "sub_points": ["...", "..."] },
            { "title": "ã€æ·±æŒ–ã€‘....", "sub_points": ["...", "..."] }
        ]
    }
    """
    
    try:
        import random
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"æ ‡é¢˜ï¼š{title}\nåˆ‡å…¥ç‚¹ï¼š{angle}\n\n(Random Seed: {random.random()})"}
            ],
            stream=False,
            temperature=0.9
        )
        
        raw = response.choices[0].message.content
        print(f"ğŸ” [å¤§çº²-åŸå§‹è¿”å›]: {raw[:100]}...") # æ‰“å°å¼€å¤´
        
        clean = extract_json(raw) # ä½¿ç”¨å¼ºåŠ›æ¸…æ´—
        data = json.loads(clean)
        
        # æ™ºèƒ½æå–æ•°æ®
        if "sections" in data:
            return data["sections"]
        # æ‰¾ä¸åˆ° sections å°±æ‰¾ç¬¬ä¸€ä¸ªåˆ—è¡¨
        for val in data.values():
            if isinstance(val, list):
                return val
                
        return _get_mock_outline(title)

    except Exception as e:
        print(f"âŒ å¤§çº²å¤±è´¥: {e}")
        return _get_mock_outline(title)

# === 2b. æ ¹æ®å¤§çº²ç”Ÿæˆå…¨æ–‡ï¼ˆè´¢ç»ç§‘æŠ€è¡Œä¸šåª’ä½“é£æ ¼ï¼‰===
def _get_mock_article(title):
    return f"""# {title}

ï¼ˆæ­¤ä¸ºæ¨¡æ‹Ÿæ­£æ–‡ã€‚è¯·é…ç½® DEEPSEEK_API_KEY åä½¿ç”¨ AI ç”Ÿæˆã€‚ï¼‰

ã€å¼€ç¯‡ã€‘å¼ºå†²çªå¼•å…¥ï¼Œç‚¹æ˜çƒ­ç‚¹ä¸äº‰è®®ã€‚
ã€ä¸»ä½“ã€‘ç°è±¡æ·±åº¦å‰–æã€æ ¸å¿ƒåŸå› æŒ–æ˜ã€è¡Œä¸šå½±å“åˆ†æã€‚
ã€ç»“å°¾ã€‘æ€»ç»“ä¸è¶‹åŠ¿é¢„åˆ¤ï¼Œå‘¼åº”è´¢ç»ç§‘æŠ€è§†è§’ã€‚
"""

def generate_article_from_outline(title, outline, context=""):
    """
    æ ¹æ®å¤§çº²ç”Ÿæˆå®Œæ•´æ–‡ç« ï¼Œé¢å‘è´¢ç»ç§‘æŠ€è¡Œä¸šåª’ä½“ã€‚
    outline: å¯ä»¥æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œæˆ– [{ "title": "ç« èŠ‚å", "sub_points": [] }] ç»“æ„
    """
    if not client:
        return _get_mock_article(title)
    print(f"âœï¸ AI æˆæ–‡: {title}")
    # å°† outline è½¬ä¸ºå¯è¯»æ–‡æœ¬
    if isinstance(outline, list) and outline and isinstance(outline[0], dict):
        outline_text = "\n".join(
            f"{i+1}. {s.get('title', '')} " + (" ".join(s.get("sub_points", [])) or "")
            for i, s in enumerate(outline)
        )
    elif isinstance(outline, list):
        outline_text = "\n".join(f"{i+1}. {s}" for i, s in enumerate(outline))
    else:
        outline_text = str(outline)
    system_prompt = """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰æ·±åšè¡Œä¸šç§¯æ·€çš„é’›åª’ä½“ï¼ˆTMTPostï¼‰èµ„æ·±ä¸»ç¬”ã€‚ä½ æ“…é•¿è§‚å¯ŸæŠ€æœ¯å˜é©èƒŒåçš„å•†ä¸šåº•å±‚é€»è¾‘ï¼Œé£æ ¼å†·å³»ã€ä¸“ä¸šï¼Œæ–‡å­—å…·æœ‰ç©¿é€åŠ›ï¼Œèƒ½å¤Ÿå¹³è¡¡å•†ä¸šåˆ©ç›Šä¸äººæ–‡æ€è€ƒã€‚

Role / è§’è‰²è®¾å®š:
- é’›åª’ä½“èµ„æ·±è´¢ç»ç§‘æŠ€ä¸“æ ä½œå®¶ã€‚
- é£æ ¼ï¼šå†·å³»ã€ä¸“ä¸šã€æ•°æ®é©±åŠ¨ã€å…·æœ‰ç©¿é€åŠ›ã€‚

Tone & Style / é’›åª’ä½“è°ƒæ€§æŒ‡å—:
1. **ä¸“ä¸šä¸”çŠ€åˆ©**ï¼šé¿å…å¹³é“ºç›´å™ï¼Œå¤šæ¢è®¨â€œä¸ºä»€ä¹ˆâ€è€Œéå•çº¯æè¿°â€œæ˜¯ä»€ä¹ˆâ€ã€‚
2. **å•†ä¸šè¯­å¢ƒ**ï¼šçµæ´»è¿ç”¨å•†ä¸šæœ¯è¯­ï¼ˆå¦‚ï¼šé£è½®æ•ˆåº”ã€å­˜é‡åšå¼ˆã€èŒƒå¼è½¬ç§»ã€ä¼°å€¼é‡æ„ç­‰ï¼‰ï¼Œä½†æ‹’ç»å †ç Œè¯è—»ã€‚
3. **æ‰¹åˆ¤æ€§æ€ç»´**ï¼šåœ¨è‚¯å®šè¶‹åŠ¿çš„åŒæ—¶ï¼Œå¿…é¡»æŒ‡å‡ºæ½œåœ¨é£é™©ã€è¡Œä¸šå£å’æˆ–æ³¡æ²«ã€‚
4. **æ’ç‰ˆè§„èŒƒ**ï¼šç»“æ„æ¸…æ™°ï¼Œæ¯èŠ‚æ ‡é¢˜è¦å…·æœ‰â€œé«˜åº¦æ¦‚æ‹¬æ€§â€å’Œâ€œå†²å‡»åŠ›â€ã€‚

Article Structure / æ–‡ç« ç»“æ„è¦æ±‚:
1. **æ ‡é¢˜ä¼˜åŒ–**ï¼šå³ä½¿ç»™å®šäº†æ ‡é¢˜ï¼Œä¹Ÿè¯·åœ¨æ–‡ç« æœ€å¼€å¤´æ¨è 1-2 ä¸ªæ›´å…·å¸å¼•åŠ›çš„å¤‡é€‰æ ‡é¢˜ï¼ˆä»¥ > å¼•ç”¨æ ¼å¼å±•ç¤ºï¼‰ã€‚
2. **æ ¸å¿ƒæ‘˜è¦**ï¼šå¼€å¤´éœ€åŒ…å« 150 å­—ä»¥å†…çš„æ ¸å¿ƒæ‘˜è¦ï¼Œæ¦‚æ‹¬æ ¸å¿ƒè§‚ç‚¹ã€‚
3. **å¼ºåŠ›å¼•è¨€ï¼ˆLead Paragraphï¼‰**ï¼š
   - æ–‡ç« å¼€å¤´å¿…é¡»åŒ…å«é«˜è´¨é‡å¯¼è¯­ï¼ˆ200-300å­—ï¼‰ã€‚
   - ä»¥è¡Œä¸šé‡å¤§äº‹ä»¶æˆ–ç»†å¾®çš„å¸‚åœºå¼‚åŠ¨åˆ‡å…¥ï¼Œå¼•å‡ºèƒŒåçš„æ·±å±‚çŸ›ç›¾ã€‚
4. **æ­£æ–‡ï¼ˆæ·±åº¦æ‹†è§£ï¼‰**ï¼š
   - ä¸¥æ ¼éµå¾ªæä¾›çš„å¤§çº²è¿›è¡Œåˆ†æ®µè®ºè¿°ã€‚
   - åŒ…å«å¯¹ç«å“çš„æ¨ªå‘å¯¹æ¯”åˆ†æã€‚
   - æ•°æ®æè¿°éœ€ç²¾å‡†ï¼Œè§‚ç‚¹éœ€æœ‰äº‹å®ä¾æ®ã€‚
5. **é’›åº¦ç»“è¯­**ï¼š
   - ç»™å‡ºç‹¬å®¶åˆ¤æ–­ã€‚æ‹’ç»é¸¡æ±¤ï¼Œè¦ç»™å‡ºå¯¹è¡Œä¸šä»ä¸šè€…çš„è­¦ç¤ºæˆ–ç­–ç•¥å»ºè®®ã€‚

Constraints / çº¦æŸæ¡ä»¶:
- ä¸¥ç¦å‡ºç°â€œåœ¨å½“ä»Šç¤¾ä¼šâ€ã€â€œä¸å¾—ä¸è¯´â€ã€â€œç¬”è€…è®¤ä¸ºâ€ç­‰å­¦ç”Ÿæ°”è¯æ±‡ã€‚
- ä½¿ç”¨ Markdown æ ¼å¼æ¸²æŸ“ã€‚
- å­—æ•°ï¼š1500 - 2500 å­—ã€‚
"""
    user_content = f"æ ‡é¢˜ï¼š{title}\n\nå¤§çº²ç»“æ„ï¼š\n{outline_text}\n\nè¡¥å……èƒŒæ™¯/ä¸Šä¸‹æ–‡ï¼š{context[:1000] if context else 'æ— '}"
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            stream=False,
            max_tokens=4000
        )
        raw = response.choices[0].message.content
        return (raw or "").strip() or _get_mock_article(title)
    except Exception as e:
        print(f"âŒ æˆæ–‡å¤±è´¥: {e}")
        return _get_mock_article(title)

# === 3. èˆ†æƒ…é£é™©ç ”åˆ¤ (Risk Assessment) ===
def analyze_risk_assessment(text, target_entity):
    """
    åˆ†ææ–‡æœ¬å¯¹è‡ªå·±å“ç‰Œçš„é£é™©ç¨‹åº¦ï¼Œæå–çœŸå®çš„é£é™©å…³é”®è¯
    """
    if not client: 
        return {
            "score": 0,
            "risk_keywords": [],
            "reason": "Mockæ¨¡å¼: æœªé…ç½®AI"
        }
        
    print(f"âš ï¸ AI èˆ†æƒ…ç ”åˆ¤: {target_entity} in {text[:20]}...")
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±èˆ†æƒ…åˆ†æå¸ˆã€‚è¯·åˆ†æç»™å®šæ–‡æœ¬å¯¹ç›®æ ‡ä¸»ä½“(target)çš„èˆ†æƒ…é£é™©ã€‚
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    - score: æƒ…æ„Ÿå€¾å‘åˆ†æ•°ï¼ŒèŒƒå›´ -1.0(æåº¦è´Ÿé¢/å±æœº) åˆ° 1.0(æåº¦æ­£é¢/åˆ©å¥½)ï¼Œ0ä¸ºä¸­æ€§ã€‚
    - risk_keywords: å­—ç¬¦ä¸²æ•°ç»„ï¼Œæå–1-3ä¸ªæ ¸å¿ƒé£é™©å…³é”®è¯ï¼ˆå¦‚"åˆ¹è½¦å¤±çµ"ã€"è´¢åŠ¡é€ å‡"ï¼‰ï¼Œå¦‚æœæ˜¯æ­£é¢æˆ–æ— é£é™©åˆ™ä¸ºç©ºæ•°ç»„ã€‚
    - reason: ç®€çŸ­çš„ä¸€å¥è¯åˆ¤æ–­ä¾æ®ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç›®æ ‡ä¸»ä½“ï¼š{target_entity}\næ–‡æœ¬å†…å®¹ï¼š{text}"}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # å…œåº•æ£€æŸ¥
        if "score" not in data: data["score"] = 0
        if "risk_keywords" not in data: data["risk_keywords"] = []
        
        return data

    except Exception as e:
        print(f"âŒ ç ”åˆ¤å¤±è´¥: {e}")
        return {
            "score": 0, 
            "risk_keywords": [],
            "reason": f"AIåˆ†æå¼‚å¸¸: {str(e)}"
        }

# === 4. æ–°é—»æ ¸å¿ƒæç‚¼ (List Summary) ===
def _get_mock_summary(title):
    return {
        "fact": f"{title} äº‹ä»¶æŒç»­å‘é…µï¼Œæ ¸å¿ƒåœ¨äºå…¶å¯¹ä¼ ç»Ÿæ¨¡å¼çš„é¢ è¦†ã€‚",
        "angle": "1. ã€Šæ·±æŒ–ï¼š{title} èƒŒåçš„èµ„æœ¬å±€ã€‹\n2. ã€Š{title}ï¼šä¸€åœºè¢«ä½ä¼°çš„å˜é©ã€‹\n3. ã€Šæ™®é€šäººå¦‚ä½•åœ¨ {title} ä¸­åˆ†ä¸€æ¯ç¾¹ï¼Ÿã€‹",
        "category": "ç»¼åˆ",
        "tags": ["çƒ­ç‚¹", "è¶‹åŠ¿"]
    }

def generate_news_summary(title, content=""):
    """
    æ ¹æ®ç”¨æˆ·ä¸“ç”¨æç¤ºè¯ï¼Œç”Ÿæˆ 'äº‹å®' + 'è§’åº¦' + 'åˆ†ç±»' + 'æ ‡ç­¾' json
    """
    if not client: return _get_mock_summary(title)
    
    # æ„é€ å†…å®¹
    full_text = f"æ ‡é¢˜ï¼š{title}\nå†…å®¹æ‘˜è¦ï¼š{content[:800]}"
    print(f"ğŸ—ï¸ AI æç‚¼æ–°é—»: {title}")

    categories_str = "ç¤¾ä¼šã€ç§‘æŠ€ã€è´¢ç»ã€é‡‘èã€æ±½è½¦ã€å¤§å¥åº·ã€æ–°æ¶ˆè´¹ã€åˆ›æŠ•ã€å¨±ä¹ã€å®è§‚ã€å‡ºæµ·ã€åœ°æ–¹ã€å›½é™…ã€å¤§å…¬å¸ã€å¤§æ¨¡å‹ã€ä½“è‚²ã€å†›äº‹ã€ä¸‰å†œã€å†œæ‘ã€éŸ³ä¹ã€ç”µå½±ã€æƒ…æ„Ÿã€æ—…æ¸¸ã€æ¸¸æˆã€å®¶å±…ã€ç»¼è‰ºã€è‚¡ç¥¨ã€å½©ç¥¨ã€æ•™è‚²ã€æ–‡åŒ–ã€ç§‘å­¦ã€ä¼ åª’ã€ç”Ÿæ´»"

    system_prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±ä¸»ç¼–ï¼Œè¯·å¯¹æ–°é—»è¿›è¡Œæç®€æç‚¼ã€é€‰é¢˜ç­–åˆ’åŠç²¾å‡†åˆ†ç±»ã€‚
    
    ä»»åŠ¡ï¼š
    1. ã€äº‹å® (fact)ã€‘ï¼šå¯¹æ–°é—»è¿›è¡Œå»æƒ…ç»ªåŒ–å¤„ç†ï¼Œç”¨ä¸€å¥è¯ï¼ˆ30å­—ä»¥å†…ï¼‰ç›´å‡»æ ¸å¿ƒäº‹ä»¶éª¨æ¶ï¼Œæ‹’ç»ä»»ä½•åºŸè¯ã€‚
    2. ã€è§’åº¦ (angle)ã€‘ï¼šç»™å‡º 3 ä¸ªä¸åŒç»´åº¦çš„çˆ†æ¬¾é€‰é¢˜æ ‡é¢˜å»ºè®®ï¼ŒæŒ‰ `1. xxx\\n2. xxx\\n3. xxx` æ ¼å¼è¾“å‡ºã€‚
    3. ã€åˆ†ç±» (category)ã€‘ï¼šåŸºäºæ–°é—»äº‹å®è¯­ä¹‰ï¼Œä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç²¾å‡†çš„ä¸€ä¸ªåˆ†ç±»ï¼š[{categories_str}]ã€‚
    4. ã€æ ‡ç­¾ (tags)ã€‘ï¼šæ ¹æ®å†…å®¹æå– 3-5 ä¸ªå…³é”®å®ä½“æˆ–ä¸»é¢˜æ ‡ç­¾ï¼ˆæ•°ç»„ï¼‰ã€‚
    
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    {{
        "fact": "30å­—ä»¥å†…çš„æ ¸å¿ƒäº‹ä»¶éª¨æ¶...",
        "angle": "1. ...\\n2. ...",
        "category": "ç§‘æŠ€",
        "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
    }}
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": full_text}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # Fallback defaults
        mock = _get_mock_summary(title)
        if "fact" not in data: data["fact"] = mock["fact"]
        if "angle" not in data: data["angle"] = mock["angle"]
        if "category" not in data: data["category"] = "ç»¼åˆ"
        if "tags" not in data: data["tags"] = []
        
        return data

    except Exception as e:
        print(f"âŒ æ–°é—»æç‚¼å¤±è´¥: {e}")
        return _get_mock_summary(title)

# === 5. äº‹ä»¶è„‰ç»œæ¢³ç† (Event Pulse) ===
def _get_mock_pulse(title):
    return {
        "facts": f"{title} çš„æ ¸å¿ƒäº‹å®æ¦‚è¦ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰ã€‚",
        "controversy": "1. äº‰è®®ç‚¹ä¸€ï¼š... \n2. äº‰è®®ç‚¹äºŒï¼š...",
        "timeline": [
            {"time": "6å°æ—¶å‰", "event": "äº‹ä»¶é¦–æ¬¡æ›å…‰ï¼Œå…³æ³¨åº¦ä¸Šå‡"},
            {"time": "2å°æ—¶å‰", "event": "ç›¸å…³æ–¹ä½œå‡ºå›åº”ï¼Œå¼•å‘è®¨è®º"},
            {"time": "30åˆ†é’Ÿå‰", "event": "çƒ­åº¦æŒç»­å‘é…µï¼Œå¤šæ–¹è§‚ç‚¹åšå¼ˆ"}
        ],
        "suggestion": "å»ºè®®ä»äº‰è®®ç‚¹åˆ‡å…¥è¿›è¡Œæ·±åº¦åˆ†æã€‚"
    }

def generate_event_pulse(title, content=""):
    """
    ç”Ÿæˆäº‹ä»¶è„‰ç»œã€äº‰è®®ç‚¹ã€æ—¶é—´çº¿å’Œå»ºè®®
    """
    if not client: return _get_mock_pulse(title)
    
    print(f"ğŸ“ˆ AI è„‰ç»œåˆ†æ: {title}")
    
    full_text = f"æ ‡é¢˜ï¼š{title}\nå†…å®¹æ‘˜è¦ï¼š{content[:1000]}"
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±è°ƒæŸ¥è®°è€…ã€‚è¯·å¯¹ç»™å®šçš„çƒ­ç‚¹äº‹ä»¶æ¢³ç†å‡ºæ¸…æ™°çš„è„‰ç»œã€‚
    
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    {
        "facts": "æ ¸å¿ƒäº‹å®ç®€è¿°ï¼ˆ50å­—å†…ï¼‰",
        "controversy": "åˆ—å‡º1-2ä¸ªæ ¸å¿ƒäº‰è®®ç‚¹æˆ–ç–‘é—®ç‚¹",
        "timeline": [
            {"time": "æ¨æµ‹æ—¶é—´ç‚¹ (å¦‚'2å°æ—¶å‰'æˆ–å…·ä½“æ—¥æœŸ)", "event": "å…³é”®èŠ‚ç‚¹äº‹ä»¶æè¿°"},
            {"time": "...", "event": "..."}
        ],
        "suggestion": "ä¸€å¥è¯åˆ›ä½œåˆ‡å…¥å»ºè®®"
    }
    
    è¦æ±‚ï¼š
    1. timeline æ•°ç»„åŒ…å« 3 ä¸ªå…³é”®èŠ‚ç‚¹ã€‚
    2. åŸºäºå¸¸è¯†æ¨ç†æˆ–å†…å®¹è¿›è¡Œåˆç†çš„å› æœæ¨æ¼”ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": full_text}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        print(f"ğŸ” [è„‰ç»œ-åŸå§‹è¿”å›]: {raw[:100]}...")
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # Validation
        if "facts" not in data or "timeline" not in data:
            return _get_mock_pulse(title)
            
        return data
        
    except Exception as e:
        print(f"âŒ è„‰ç»œåˆ†æå¤±è´¥: {e}")
        return _get_mock_pulse(title)


# === 6. çƒ­è¯æå– (Keyword Extraction) ===
def extract_keywords_from_content(content: str, max_keywords: int = 8):
    """
    ä»èˆ†æƒ…å†…å®¹ä¸­æå–æ ¸å¿ƒçƒ­è¯åŠAIè§‚ç‚¹
    """
    if not client:
        # æ— AIæ—¶ä½¿ç”¨jiebaåˆ†è¯
        import jieba
        from collections import Counter
        words = [w for w in jieba.cut(content) if len(w) >= 2]
        word_counts = Counter(words).most_common(max_keywords)
        return [
            {"keyword": word, "opinion": f"å‡ºç°{count}æ¬¡", "count": count}
            for word, count in word_counts
        ]
    
    try:
        prompt = f"""åˆ†æä»¥ä¸‹èˆ†æƒ…å†…å®¹ï¼Œæå–6-8ä¸ªæ ¸å¿ƒçƒ­è¯ï¼Œå¹¶ä¸ºæ¯ä¸ªçƒ­è¯ç”Ÿæˆç®€çŸ­çš„AIè§‚ç‚¹æ€»ç»“ã€‚

å†…å®¹:
{content[:3000]}

è¯·è¿”å›JSONæ ¼å¼:
{{
  "keywords": [
    {{"keyword": "å…³é”®è¯1", "opinion": "AIè§‚ç‚¹: ä¸€å¥è¯æ€»ç»“ç”¨æˆ·å¯¹è¯¥è¯çš„çœ‹æ³•"}},
    {{"keyword": "å…³é”®è¯2", "opinion": "AIè§‚ç‚¹: ä¸€å¥è¯æ€»ç»“"}}
  ]
}}

æ³¨æ„:
1. å…³é”®è¯åº”è¯¥æ˜¯å†…å®¹ä¸­è®¨è®ºæœ€é¢‘ç¹çš„è¯é¢˜
2. AIè§‚ç‚¹è¦ç®€æ´ï¼Œä¸è¶…è¿‡20ä¸ªå­—
3. æŒ‰é‡è¦æ€§æ’åºï¼Œæœ€é‡è¦çš„æ’åœ¨å‰é¢
"""
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èˆ†æƒ…åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»å¤§é‡æ–‡æœ¬ä¸­æå–æ ¸å¿ƒè¯é¢˜å’Œå…¬ä¼—è§‚ç‚¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.3
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        return data.get("keywords", [])[:max_keywords]
        
    except Exception as e:
        print(f"âŒ çƒ­è¯æå–å¤±è´¥: {e}")
        # Fallback to jieba
        import jieba
        from collections import Counter
        words = [w for w in jieba.cut(content) if len(w) >= 2]
        word_counts = Counter(words).most_common(max_keywords)
        return [
            {"keyword": word, "opinion": f"å‡ºç°{count}æ¬¡", "count": count}
            for word, count in word_counts
        ]
# === 7. æ™ºèƒ½æ¶¦è‰² (Smart Polish) ===
def _get_mock_polish_result(text_preview):
    return f"""# æ·±åº¦è®¿è°ˆï¼šé‡å¡‘æœªæ¥çš„åŠ›é‡

ï¼ˆæ³¨ï¼šç³»ç»Ÿæœªé…ç½®AI Keyï¼Œä»¥ä¸‹ä¸ºæ ¹æ®è¾“å…¥ç”Ÿæˆçš„æ¨¡æ‹Ÿæ¶¦è‰²ç¨¿ï¼‰

åœ¨å½“ä»Šå¿«é€Ÿå˜åŒ–çš„å•†ä¸šç‰ˆå›¾ä¸­ï¼Œæˆ‘ä»¬æœ‰å¹¸é‡‡è®¿åˆ°äº†ç›¸å…³é¢†åŸŸçš„ä¸“å®¶ã€‚åœ¨è¿™æ¬¡æ·±å…¥çš„å¯¹è¯ä¸­ï¼Œå‡ ä¸ªæ ¸å¿ƒè§‚ç‚¹é€æ¸æ¸…æ™°......

## æ ¸å¿ƒè§‚ç‚¹ä¸€ï¼šæ‰“ç ´å¸¸è§„
å³ä½¿{{text_preview[:20]}}... 
ä¸“å®¶æŒ‡å‡ºï¼Œå”¯æœ‰åˆ›æ–°æ‰èƒ½åœ¨æ¿€çƒˆçš„å¸‚åœºç«äº‰ä¸­ç«‹è¶³ã€‚è¿™ä¸ä»…ä»…æ˜¯æŠ€æœ¯å±‚é¢çš„é©æ–°ï¼Œæ›´æ˜¯æ€ç»´æ¨¡å¼çš„è½¬å˜ã€‚

## æ ¸å¿ƒè§‚ç‚¹äºŒï¼šç”¨æˆ·è‡³ä¸Š
æˆ‘ä»¬çœ‹åˆ°ï¼Œ{{text_preview[20:40] if len(text_preview)>40 else "å¸‚åœºåé¦ˆ"}}...
çœŸæ­£ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œæ¯”å•çº¯å †ç ŒåŠŸèƒ½æ›´ä¸ºé‡è¦ã€‚

## ç»“è¯­
æœªæ¥çš„é“è·¯å……æ»¡æŒ‘æˆ˜ï¼Œä½†ä¹Ÿè•´å«æœºé‡ã€‚

---
*æœ¬æ–‡åŸºäºé‡‡è®¿é€Ÿè®°æ•´ç†æ¶¦è‰²ï¼Œæ—¨åœ¨è¿˜åŸå¯¹è¯ç²¾é«“å¹¶æå‡é˜…è¯»ä½“éªŒã€‚*
"""


# === 7. æ™ºèƒ½æ¶¦è‰² (Smart Polish) ===
def _get_mock_polish_result(text_preview):
    return {
        "title": "æ·±åº¦è®¿è°ˆï¼šé‡å¡‘æœªæ¥çš„åŠ›é‡",
        "summary": "æœ¬æ–‡åŸºäºå¯¹è¡Œä¸šä¸“å®¶çš„æ·±åº¦è®¿è°ˆï¼Œæ¢è®¨äº†åœ¨å¿«é€Ÿå˜åŒ–çš„å•†ä¸šç‰ˆå›¾ä¸­ï¼Œåˆ›æ–°æ€ç»´ä¸ç”¨æˆ·è‡³ä¸Šç†å¿µå¦‚ä½•æˆä¸ºä¼ä¸šç ´å±€çš„å…³é”®ã€‚",
        "content": f"""<h2>æ ¸å¿ƒè§‚ç‚¹ä¸€ï¼šæ‰“ç ´å¸¸è§„</h2>
<p>å³ä½¿{text_preview[:20]}... ä¸“å®¶æŒ‡å‡ºï¼Œå”¯æœ‰åˆ›æ–°æ‰èƒ½åœ¨æ¿€çƒˆçš„å¸‚åœºç«äº‰ä¸­ç«‹è¶³ã€‚</p>
<p>è¿™ä¸ä»…ä»…æ˜¯æŠ€æœ¯å±‚é¢çš„é©æ–°ï¼Œæ›´æ˜¯æ€ç»´æ¨¡å¼çš„è½¬å˜ã€‚ä¼ä¸šéœ€è¦è·³å‡ºèˆ’é€‚åŒºï¼Œå‹‡äºå°è¯•æ–°çš„å•†ä¸šæ¨¡å¼ã€‚</p>
<br>
<h2>æ ¸å¿ƒè§‚ç‚¹äºŒï¼šç”¨æˆ·è‡³ä¸Š</h2>
<p>æˆ‘ä»¬çœ‹åˆ°ï¼Œ{text_preview[20:40] if len(text_preview)>40 else "å¸‚åœºåé¦ˆ"}... çœŸæ­£ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œæ¯”å•çº¯å †ç ŒåŠŸèƒ½æ›´ä¸ºé‡è¦ã€‚</p>
<p>ç”¨æˆ·ä¸ä»…ä»…æ˜¯æ¶ˆè´¹è€…ï¼Œæ›´æ˜¯äº§å“çš„å…±å»ºè€…ã€‚å€¾å¬ç”¨æˆ·çš„å£°éŸ³ï¼Œæ˜¯äº§å“è¿­ä»£çš„æœ€ä½³æŒ‡å¼•ã€‚</p>
<br>
<h2>ç»“è¯­</h2>
<p>æœªæ¥çš„é“è·¯å……æ»¡æŒ‘æˆ˜ï¼Œä½†ä¹Ÿè•´å«æœºé‡ã€‚è®©æˆ‘ä»¬æºæ‰‹å…±è¿›ï¼Œåˆ›é€ è¾‰ç…Œã€‚</p>"""
    }

def polish_interview_notes(content: str, instruction: str = None):
    """
    å°†é‡‡è®¿é€Ÿè®°æ¶¦è‰²ä¸ºé•¿æ–‡ï¼Œè¿”å› { title, summary, content }
    """
    if not client:
        return _get_mock_polish_result(content)
    
    print(f"ğŸ’… AI æ¶¦è‰²ä¸­ï¼Œé•¿åº¦: {len(content)}")
    
    # Base system prompt with JSON formatting requirements
    base_prompt = """ä½ æ˜¯ä¸€ä½é’›åª’ä½“ï¼ˆTMTPostï¼‰çš„èµ„æ·±ç‰¹ç¨¿ç¼–è¾‘ã€‚æˆ‘å°†æä¾›ä¸€ä»½é‡‡è®¿é€Ÿè®°/è‰ç¨¿ï¼Œè¯·ä½ å°†å…¶æ¶¦è‰²æ”¹å†™æˆä¸€ç¯‡æ·±åº¦äº§ä¸šè§‚å¯Ÿæ–‡ç« ã€‚
    
è¯·è¿”å› JSON æ ¼å¼ï¼š
{
    "title": "ç¬¦åˆé’›åª’ä½“è°ƒæ€§çš„ä¸“ä¸šå¤§æ ‡é¢˜ï¼ˆçªå‡ºäº§ä¸šæ´å¯Ÿå’ŒçŠ€åˆ©è§‚ç‚¹ï¼‰",
    "summary": "200å­—ä»¥å†…çš„æ–‡ç« æ‘˜è¦ï¼ˆå‡ç»ƒæ ¸å¿ƒä»·å€¼ä¸è¡Œä¸šå½±å“ï¼‰",
    "content": "HTMLæ ¼å¼çš„æ­£æ–‡ï¼ŒåŒ…å« <h2>å°æ ‡é¢˜</h2>ã€<p>æ®µè½</p> ç­‰æ ‡ç­¾ã€‚å­—æ•°è¦æ±‚ 1500-2000 å­—ã€‚"
}"""

    # If instruction is provided, use it as the main guideline. 
    # Otherwise, fallback to the default rigorous logic.
    if instruction:
        writing_logic = f"""
å†™ä½œè¦æ±‚ (åŸºäºç”¨æˆ·æŒ‡ä»¤):
{instruction}

é€šç”¨è¦æ±‚ï¼š
1. å¿…é¡»è¿”å› JSON æ ¼å¼ã€‚
2. ä¿æŒ HTML æ ‡ç­¾ç»“æ„ã€‚
"""
    else:
        writing_logic = """
å†™ä½œé€»è¾‘ä¸è¦æ±‚ï¼š
1. **ç»“æ„é‡ç»„**ï¼šå¿…é¡»ä¸¥æ ¼éµå¾ªã€è¶‹åŠ¿æ´å¯Ÿ -> ä¼ä¸šè½åœ° -> åœ†æ¡Œå…±è¯†ã€‘çš„é€»è¾‘è¿›è¡Œé‡æ„ã€‚
    - **è¶‹åŠ¿æ´å¯Ÿ**ï¼šä»è¡Œä¸šå®è§‚è§†è§’åˆ‡å…¥ï¼Œç‚¹å‡º AI æ—¶ä»£çŸ¥è¯†æ²»ç†çš„ç´§è¿«æ€§ä¸æ ¸å¿ƒä»·å€¼ã€‚
    - **ä¼ä¸šè½åœ°**ï¼šç»“åˆå˜‰å®¾åˆ†äº«çš„å®è·µç»éªŒï¼Œè¯¦ç»†é˜è¿°å…·ä½“è½åœ°è·¯å¾„ã€æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆã€‚
    - **åœ†æ¡Œå…±è¯†**ï¼šå‡åä¸»é¢˜ï¼Œæç‚¼è¡Œä¸šå…±è¯†ï¼Œå±•æœ›æœªæ¥è¶‹åŠ¿ã€‚
2. **è¯­è¨€é£æ ¼**ï¼š
    - **TMTPost è°ƒæ€§**ï¼šç§‘æŠ€äº§ä¸šæ·±åº¦ã€çŠ€åˆ©æ´å¯Ÿã€ä¸“ä¸šç²¾ç‚¼ã€‚
    - **å»å£è¯­åŒ–**ï¼šå½»åº•å‰”é™¤â€œå—¯ã€å‘ƒã€ç„¶åâ€ç­‰å£è¯­ï¼Œå°†å¯¹è¯è½¬åŒ–ä¸ºé€»è¾‘ä¸¥å¯†çš„ä¹¦é¢è¡¨è¾¾ã€‚
    - **çŠ€åˆ©ç‚¹è¯„**ï¼šé€‚å½“å¢åŠ â€œé’›åª’ä½“æ³¨â€æˆ–ä¸»ç¼–ç‚¹è¯„è§†è§’çš„é‡‘å¥ï¼Œå¼ºåŒ–æ–‡ç« çš„è§‚ç‚¹åŠ›åº¦ã€‚
3. **å†…å®¹ä¼˜åŒ–**ï¼š
    - **æç‚¼æ´å¯Ÿ**ï¼šä¸è¦è®°æµæ°´è´¦ï¼Œè¦æç‚¼å˜‰å®¾è§‚ç‚¹èƒŒåçš„è¡Œä¸šé€»è¾‘ã€‚
    - **çªå‡ºä»·å€¼**ï¼šé‡ç‚¹å¼ºåŒ–â€œAIæ—¶ä»£çŸ¥è¯†æ²»ç†â€çš„æ ¸å¿ƒä»·å€¼ã€‚
    - **æ•°æ®ä¸æ¡ˆä¾‹**ï¼šä¿ç•™å¹¶çªå‡ºåŸæ–‡ä¸­çš„å…³é”®æ•°æ®å’Œå…·ä½“æ¡ˆä¾‹ã€‚
"""

    system_prompt = f"{base_prompt}\n{writing_logic}"
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat", 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"é‡‡è®¿é€Ÿè®°å†…å®¹ï¼š\n\n{content[:5000]}"}
            ],
            stream=False,
            max_tokens=4000
        )
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        return json.loads(clean)
    except Exception as e:
        print(f"âŒ æ¶¦è‰²å¤±è´¥: {e}")
        return _get_mock_polish_result(content)

def refine_article_with_chat(current_content, instruction):
    """
    æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ä¼˜åŒ–æ–‡ç« å†…å®¹
    """
    if not client:
        return f"{current_content}\n<p>ï¼ˆMockï¼šå·²æ ¹æ®æŒ‡ä»¤â€œ{instruction}â€ä¼˜åŒ–å†…å®¹ï¼‰</p>"
        
    print(f"ğŸ¤– AI ä¼˜åŒ–æ–‡ç« : {instruction}")
    
    system_prompt = """ä½ æ˜¯ä¸€ä½é’›åª’ä½“ï¼ˆTMTPostï¼‰çš„ä¸“ä¸šæ–‡ç« ä¼˜åŒ–åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ä¿®æ”¹æŒ‡ä»¤ï¼Œå¯¹å½“å‰æ–‡ç« å†…å®¹è¿›è¡Œè°ƒæ•´æˆ–é‡å†™ã€‚

æ ¸å¿ƒè°ƒæ€§è¦æ±‚ï¼š
1. **ç§‘æŠ€äº§ä¸šæ·±åº¦**ï¼šä¿æŒå¯¹è¡Œä¸šè¶‹åŠ¿çš„æ•é”æ´å¯Ÿï¼Œæ‹’ç»è‚¤æµ…çš„æè¿°ã€‚
2. **çŠ€åˆ©æ´å¯Ÿ**ï¼šè¯­è¨€è¦å¹²ç»ƒã€æœ‰åŠ›ï¼Œç›´å‡»é—®é¢˜æœ¬è´¨ã€‚
3. **ä¸“ä¸šè´¨æ„Ÿ**ï¼šä½¿ç”¨å‡†ç¡®çš„è¡Œä¸šæœ¯è¯­ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œè¡Œæ–‡æµç•…ã€‚

è¯·ç›´æ¥è¿”å›ä¿®æ”¹åçš„ HTML æ­£æ–‡å†…å®¹ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°æˆ– JSON æ ¼å¼ã€‚
ä¿æŒåŸæœ‰çš„ HTML æ ‡ç­¾ç»“æ„ï¼ˆh2, p ç­‰ï¼‰ã€‚"""
def generate_cover_image(title, content=""):
    """
    æ ¹æ®æ–‡ç« å†…å®¹ç”Ÿæˆå°é¢å›¾
    1. å…ˆè®© LLM ç”Ÿæˆç»˜ç”»æç¤ºè¯
    2. è°ƒç”¨ç»˜å›¾æ¥å£ (DALL-E 3 or Compatible)
    """
    if not client:
        return "https://images.unsplash.com/photo-1518770660439-4636190af475?ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=80"
    
    print(f"ğŸ¨ AI ç”Ÿæˆå°é¢å›¾ä¸­: {title}")
    
    # 1. Generate Prompt
    prompt_gen_messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè§†è§‰è‰ºæœ¯æ€»ç›‘ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æ–‡ç« æ ‡é¢˜å’Œæ‘˜è¦ï¼Œè®¾è®¡ä¸€ä¸ªå¯Œæœ‰ç§‘æŠ€æ„Ÿã€ç°ä»£æ„Ÿä¸”æŠ½è±¡çš„å°é¢å›¾ç”Ÿæˆæç¤ºè¯(Prompt)ã€‚\nè¦æ±‚ï¼š\n1. è‹±æ–‡æè¿°ã€‚\n2. åŒ…å«å…·ä½“çš„è‰ºæœ¯é£æ ¼ï¼ˆå¦‚ï¼šCyberpunk, Minimalist, 3D Render, Abstract tech linesï¼‰ã€‚\n3. é€‚åˆä½œä¸º 16:9 çš„æ–‡ç« å°é¢ã€‚\n4. ç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚"},
        {"role": "user", "content": f"æ–‡ç« æ ‡é¢˜ï¼š{title}\n\nå†…å®¹æ‘˜è¦ï¼š{content[:500]}"}
    ]
    
    try:
        # Step 1: Get Visual Prompt
        resp = client.chat.completions.create(
            model="deepseek-chat", # Use standard chat model for prompt gen
            messages=prompt_gen_messages,
            max_tokens=200
        )
        visual_prompt = resp.choices[0].message.content
        print(f"ğŸ¨ [å°é¢Prompt]: {visual_prompt}")
        
        # Step 2: Generate Image
        # Note: Depending on the provider (DeepSeek vs OpenAI), images.generate might not work.
        # We try to call it standard OpenAI style. If it fails, we fall back.
        try:
            img_resp = client.images.generate(
                model="dall-e-3",
                prompt=visual_prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            return img_resp.data[0].url
        except Exception as img_err:
            print(f"âš ï¸ ç»˜å›¾æ¥å£è°ƒç”¨å¤±è´¥ (å¯èƒ½ä¸æ”¯æŒ Image API): {img_err}")
            # Fallback 1: Try mocking or using a keyword based image service
            # Let's extract a keyword for Unsplash
            import random
            keyword = "technology"
            return f"https://source.unsplash.com/1600x900/?{keyword},{random.randint(1,100)}"

    except Exception as e:
        print(f"âŒ å°é¢ç”Ÿæˆå¤±è´¥: {e}")
        return "https://images.unsplash.com/photo-1451187580459-43490279c0fa?auto=format&fit=crop&w=1600&q=80"


def smart_parse_topic(user_input: str) -> str:
    """
    ä»ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸­æå–æ ¸å¿ƒé€‰é¢˜/è¯é¢˜ã€‚
    ä¾‹å¦‚ï¼š"å†™ä¸€ç¯‡å…³äºç™¾åº¦èŠ¯ç‰‡çš„æ–‡ç« " -> "ç™¾åº¦èŠ¯ç‰‡"
    """
    if not client:
        t = user_input.replace("å†™ä¸€ç¯‡", "").replace("çš„æ–‡ç« ", "").replace("å…³äº", "").strip()
        return t if t else user_input
    
    try:
        completion = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å†™ä½œåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„è¾“å…¥ï¼Œæå–å‡ºç”¨æˆ·çœŸæ­£æƒ³å†™çš„æ ¸å¿ƒè¯é¢˜æˆ–ä¸»é¢˜ï¼ˆTopicï¼‰ã€‚
è§„åˆ™ï¼š
1. å»é™¤æ‰€æœ‰æŒ‡ä»¤æ€§è¯æ±‡ï¼Œå¦‚â€œå¸®æˆ‘å†™ä¸€ç¯‡â€ã€â€œå…³äºâ€ã€â€œä½ è§‰å¾—â€ã€â€œåˆ†æä¸€ä¸‹â€ã€â€œå†™ä¸ªæ–‡ç« â€ç­‰ã€‚
2. å³ä½¿åŒ…å«â€œä½ è§‰å¾—xxxæ€ä¹ˆæ ·â€ï¼Œæ ¸å¿ƒè¯é¢˜ä¹Ÿæ˜¯â€œxxxâ€ã€‚
3. ä»…è¿”å›æç‚¼åçš„æ ¸å¿ƒè¯é¢˜è¯ï¼Œä¸è¦åŒ…å«æ ‡ç‚¹ç¬¦å·æˆ–å…¶ä»–è§£é‡Šã€‚
4. å¦‚æœæ— æ³•æå–ï¼ˆä¾‹å¦‚è¾“å…¥ä¸ºç©ºæˆ–æ— æ„ä¹‰ï¼‰ï¼Œè¿”å›åŸè¾“å…¥ã€‚

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼šå†™ä¸€ç¯‡å…³äºç™¾åº¦èŠ¯ç‰‡çš„æ–‡ç« 
è¾“å‡ºï¼šç™¾åº¦èŠ¯ç‰‡

è¾“å…¥ï¼šä½ è§‰å¾—ç°åœ¨çš„è‚¡å¸‚æ€ä¹ˆæ ·
è¾“å‡ºï¼šå½“å‰è‚¡å¸‚è¡Œæƒ…

è¾“å…¥ï¼šå¸®æˆ‘åˆ†æä¸‹é©¬æ–¯å…‹çš„æœ€æ–°åŠ¨æ€
è¾“å‡ºï¼šé©¬æ–¯å…‹æœ€æ–°åŠ¨æ€
"""},
                {"role": "user", "content": f"è¾“å…¥: {user_input}\nè¾“å‡º:"}
            ],
            max_tokens=64
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        print(f"Topic parsing error: {e}")
        return user_input

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·æŒ‡ä»¤ï¼š{instruction}\n\nå½“å‰æ–‡ç« å†…å®¹ï¼š\n{current_content[:3000]}"}
            ],
            stream=False,
            max_tokens=3000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {e}")
        return current_content

