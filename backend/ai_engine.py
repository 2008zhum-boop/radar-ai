import os
import json
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("DEEPSEEK_API_KEY")
base_url = os.getenv("DEEPSEEK_BASE_URL")

client = None
if api_key:
    client = OpenAI(api_key=api_key, base_url=base_url)

# === çº¯æ–‡æœ¬ç”Ÿæˆï¼ˆDeepSeekï¼‰===
def call_deepseek_text(prompt: str) -> str:
    """
    è°ƒç”¨ DeepSeek è¿”å›çº¯æ–‡æœ¬ï¼Œç”¨äºå¿«æŠ¥æ”¹å†™ç­‰åœºæ™¯ã€‚
    """
    if not client:
        return ""
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èµ„æ·±è´¢ç»ç§‘æŠ€åª’ä½“ç¼–è¾‘ï¼Œè¾“å‡ºç®€æ´ä¸“ä¸šçš„å¿«è®¯æ­£æ–‡ã€‚"},
                {"role": "user", "content": prompt}
            ],
            stream=False,
            temperature=0.3
        )
        return (response.choices[0].message.content or "").strip()
    except Exception as e:
        print(f"DeepSeek text error: {e}")
        return ""

# === ğŸ›¡ï¸ å¼ºåŠ›æ¸…æ´—å‡½æ•° (æœ¬æ¬¡å‡çº§é‡ç‚¹) ===
def extract_json(text):
    """
    ä»ä¹±ä¸ƒå…«ç³Ÿçš„ AI å›å¤ä¸­ï¼Œç²¾å‡†æå–å‡º JSON éƒ¨åˆ†
    """
    if not text: return "{}"
    
    # 1. å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª '{' å’Œæœ€åä¸€ä¸ª '}'
    # re.DOTALL è®© . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦ï¼Œé˜² AI æ¢è¡Œè¾“å‡º
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        return match.group(0)
    
    # 2. å¦‚æœæ²¡æ‰¾åˆ°å¤§æ‹¬å·ï¼Œå°è¯•æ¸…ç† markdown æ ‡è®°åè¿”å›
    text = re.sub(r'```json', '', text)
    text = re.sub(r'```', '', text)
    return text.strip()

# === å…œåº•æ•°æ® ===
def _get_mock_analysis(topic):
    return {
        "topic": topic,
        "emotion": "æ¨¡æ‹Ÿæ•°æ®",
        "angles": ["è¯·æ£€æŸ¥åç«¯ç»ˆç«¯æ—¥å¿—", "JSONæå–å¯èƒ½å¤±è´¥", "Keyå¯èƒ½å¼‚å¸¸"],
        "titles": [f"æµ‹è¯•ï¼š{topic}", "ç³»ç»Ÿé™çº§ä¸ºMockæ¨¡å¼"]
    }

def _get_mock_outline(title):
    return [
        f"ã€å¼€ç¯‡ã€‘ï¼šå¼ºå†²çªå¼•å…¥ {title}", 
        "ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘ï¼šç°è±¡æ·±åº¦å‰–æ (Mockæ•°æ®)", 
        "ã€ç¬¬äºŒéƒ¨åˆ†ã€‘ï¼šæ ¸å¿ƒåŸå› æŒ–æ˜", 
        "ã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘ï¼šæœªæ¥è¶‹åŠ¿é¢„åˆ¤", 
        "ã€ç»“å°¾ã€‘ï¼šæ€»ç»“ä¸å‡å"
    ]

# === 1. åˆ†æè¯é¢˜ ===
def generate_analysis(topic):
    if not client: return _get_mock_analysis(topic)
    print(f"ğŸ§  AI åˆ†æä¸­: {topic}")
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ä¸»ç¼–ã€‚è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼šemotion(æƒ…ç»ª), angles(3ä¸ªè§’åº¦æ•°ç»„), titles(5ä¸ªæ ‡é¢˜æ•°ç»„)ã€‚ä¸è¦è¾“å‡ºä»»ä½•åºŸè¯ã€‚"},
                {"role": "user", "content": f"åˆ†æè¯é¢˜ï¼š{topic}"}
            ],
            stream=False
        )
        raw = response.choices[0].message.content
        print(f"ğŸ” [åˆ†æ-åŸå§‹è¿”å›]: {raw[:100]}...") # åªæ‰“å°å‰100å­—é˜²æ­¢åˆ·å±
        
        clean = extract_json(raw) # ä½¿ç”¨å¼ºåŠ›æ¸…æ´—
        return json.loads(clean)
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return _get_mock_analysis(topic)

# === 2. ç”Ÿæˆå¤§çº² ===
def generate_outline(title, angle):
    if not client: return _get_mock_outline(title)
    print(f"ğŸ“ AI å†™å¤§çº²: {title}")
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªå†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®æ ‡é¢˜å’Œåˆ‡å…¥ç‚¹ï¼Œç”Ÿæˆä¸€ä»½æ–‡ç« å¤§çº²ã€‚
    è¦æ±‚ï¼š
    1. è¿”å› JSON æ ¼å¼ã€‚
    2. æ ¹èŠ‚ç‚¹ key å¿…é¡»æ˜¯ "sections"ã€‚
    3. value æ˜¯ä¸€ä¸ªåŒ…å« 5-7 ä¸ªæ­¥éª¤çš„å­—ç¬¦ä¸²æ•°ç»„ã€‚
    ç¤ºä¾‹ï¼š{ "sections": ["æ­¥éª¤1...", "æ­¥éª¤2..."] }
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"æ ‡é¢˜ï¼š{title}\nåˆ‡å…¥ç‚¹ï¼š{angle}"}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        print(f"ğŸ” [å¤§çº²-åŸå§‹è¿”å›]: {raw}") # æ‰“å°å…¨éƒ¨å†…å®¹ä»¥ä¾¿è°ƒè¯•
        
        clean = extract_json(raw) # ä½¿ç”¨å¼ºåŠ›æ¸…æ´—
        data = json.loads(clean)
        
        # æ™ºèƒ½æå–æ•°æ®
        if "sections" in data:
            return data["sections"]
        # æ‰¾ä¸åˆ° sections å°±æ‰¾ç¬¬ä¸€ä¸ªåˆ—è¡¨
        for val in data.values():
            if isinstance(val, list):
                return val
                
        return _get_mock_outline(title)

    except Exception as e:
        print(f"âŒ å¤§çº²å¤±è´¥: {e}")
        return _get_mock_outline(title)

# === 3. èˆ†æƒ…é£é™©ç ”åˆ¤ (Risk Assessment) ===
def analyze_risk_assessment(text, target_entity):
    """
    åˆ†ææ–‡æœ¬å¯¹è‡ªå·±å“ç‰Œçš„é£é™©ç¨‹åº¦ï¼Œæå–çœŸå®çš„é£é™©å…³é”®è¯
    """
    if not client: 
        return {
            "score": 0,
            "risk_keywords": [],
            "reason": "Mockæ¨¡å¼: æœªé…ç½®AI"
        }
        
    print(f"âš ï¸ AI èˆ†æƒ…ç ”åˆ¤: {target_entity} in {text[:20]}...")
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±èˆ†æƒ…åˆ†æå¸ˆã€‚è¯·åˆ†æç»™å®šæ–‡æœ¬å¯¹ç›®æ ‡ä¸»ä½“(target)çš„èˆ†æƒ…é£é™©ã€‚
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    - score: æƒ…æ„Ÿå€¾å‘åˆ†æ•°ï¼ŒèŒƒå›´ -1.0(æåº¦è´Ÿé¢/å±æœº) åˆ° 1.0(æåº¦æ­£é¢/åˆ©å¥½)ï¼Œ0ä¸ºä¸­æ€§ã€‚
    - risk_keywords: å­—ç¬¦ä¸²æ•°ç»„ï¼Œæå–1-3ä¸ªæ ¸å¿ƒé£é™©å…³é”®è¯ï¼ˆå¦‚"åˆ¹è½¦å¤±çµ"ã€"è´¢åŠ¡é€ å‡"ï¼‰ï¼Œå¦‚æœæ˜¯æ­£é¢æˆ–æ— é£é™©åˆ™ä¸ºç©ºæ•°ç»„ã€‚
    - reason: ç®€çŸ­çš„ä¸€å¥è¯åˆ¤æ–­ä¾æ®ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç›®æ ‡ä¸»ä½“ï¼š{target_entity}\næ–‡æœ¬å†…å®¹ï¼š{text}"}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # å…œåº•æ£€æŸ¥
        if "score" not in data: data["score"] = 0
        if "risk_keywords" not in data: data["risk_keywords"] = []
        
        return data

    except Exception as e:
        print(f"âŒ ç ”åˆ¤å¤±è´¥: {e}")
        return {
            "score": 0, 
            "risk_keywords": [],
            "reason": f"AIåˆ†æå¼‚å¸¸: {str(e)}"
        }

# === 4. æ–°é—»æ ¸å¿ƒæç‚¼ (List Summary) ===
def _get_fallback_summary(title, content=""):
    """
    æ—  AI æ—¶çš„çœŸå®æ‘˜è¦å…œåº•ï¼šä¼˜å…ˆä½¿ç”¨æ­£æ–‡/æ‘˜è¦é¦–æ®µ
    """
    text = (content or "").strip()
    if not text:
        text = (title or "").strip()
    # å–ç¬¬ä¸€å¥/é¦–æ®µ
    if "ã€‚" in text:
        first = text.split("ã€‚")[0].strip()
        text = first + "ã€‚"
    if len(text) > 80:
        text = text[:80].rstrip() + "..."
    return {
        "fact": text,
        "angle": "",
        "category": "ç»¼åˆ",
        "tags": []
    }

def generate_news_summary(title, content=""):
    """
    æ ¹æ®ç”¨æˆ·ä¸“ç”¨æç¤ºè¯ï¼Œç”Ÿæˆ 'äº‹å®' + 'è§’åº¦' + 'åˆ†ç±»' + 'æ ‡ç­¾' json
    """
    if not client:
        return _get_fallback_summary(title, content)
    
    # æ„é€ å†…å®¹
    full_text = f"æ ‡é¢˜ï¼š{title}\nå†…å®¹æ‘˜è¦ï¼š{content[:800]}"
    print(f"ğŸ—ï¸ AI æç‚¼æ–°é—»: {title}")

    categories_str = "ç¤¾ä¼šã€ç§‘æŠ€ã€è´¢ç»ã€é‡‘èã€æ±½è½¦ã€å¤§å¥åº·ã€æ–°æ¶ˆè´¹ã€åˆ›æŠ•ã€å¨±ä¹ã€å®è§‚ã€å‡ºæµ·ã€åœ°æ–¹ã€å›½é™…ã€å¤§å…¬å¸ã€å¤§æ¨¡å‹ã€ä½“è‚²ã€å†›äº‹ã€ä¸‰å†œã€å†œæ‘ã€éŸ³ä¹ã€ç”µå½±ã€æƒ…æ„Ÿã€æ—…æ¸¸ã€æ¸¸æˆã€å®¶å±…ã€ç»¼è‰ºã€è‚¡ç¥¨ã€å½©ç¥¨ã€æ•™è‚²ã€æ–‡åŒ–ã€ç§‘å­¦ã€ä¼ åª’ã€ç”Ÿæ´»"

    system_prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±ä¸»ç¼–ï¼Œè¯·å¯¹æ–°é—»è¿›è¡Œæç®€æç‚¼ã€é€‰é¢˜ç­–åˆ’åŠç²¾å‡†åˆ†ç±»ã€‚
    
    ä»»åŠ¡ï¼š
    1. ã€äº‹å® (fact)ã€‘ï¼šå¯¹æ–°é—»è¿›è¡Œå»æƒ…ç»ªåŒ–å¤„ç†ï¼Œç”¨ä¸€å¥è¯ï¼ˆ30å­—ä»¥å†…ï¼‰ç›´å‡»æ ¸å¿ƒäº‹ä»¶éª¨æ¶ï¼Œæ‹’ç»ä»»ä½•åºŸè¯ã€‚
    2. ã€è§’åº¦ (angle)ã€‘ï¼šç»™å‡º 3 ä¸ªä¸åŒç»´åº¦çš„çˆ†æ¬¾é€‰é¢˜æ ‡é¢˜å»ºè®®ï¼ŒæŒ‰ `1. xxx\\n2. xxx\\n3. xxx` æ ¼å¼è¾“å‡ºã€‚
    3. ã€åˆ†ç±» (category)ã€‘ï¼šåŸºäºæ–°é—»äº‹å®è¯­ä¹‰ï¼Œä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç²¾å‡†çš„ä¸€ä¸ªåˆ†ç±»ï¼š[{categories_str}]ã€‚
    4. ã€æ ‡ç­¾ (tags)ã€‘ï¼šæ ¹æ®å†…å®¹æå– 3-5 ä¸ªå…³é”®å®ä½“æˆ–ä¸»é¢˜æ ‡ç­¾ï¼ˆæ•°ç»„ï¼‰ã€‚
    
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    {{
        "fact": "30å­—ä»¥å†…çš„æ ¸å¿ƒäº‹ä»¶éª¨æ¶...",
        "angle": "1. ...\\n2. ...",
        "category": "ç§‘æŠ€",
        "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
    }}
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": full_text}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # Fallback defaults
        fallback = _get_fallback_summary(title, content)
        if "fact" not in data: data["fact"] = fallback["fact"]
        if "angle" not in data: data["angle"] = fallback["angle"]
        if "category" not in data: data["category"] = "ç»¼åˆ"
        if "tags" not in data: data["tags"] = []
        
        return data

    except Exception as e:
        print(f"âŒ æ–°é—»æç‚¼å¤±è´¥: {e}")
        return _get_fallback_summary(title, content)

# === 5. äº‹ä»¶è„‰ç»œæ¢³ç† (Event Pulse) ===
def _get_mock_pulse(title):
    return {
        "facts": f"{title} çš„æ ¸å¿ƒäº‹å®æ¦‚è¦ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰ã€‚",
        "controversy": "1. äº‰è®®ç‚¹ä¸€ï¼š... \n2. äº‰è®®ç‚¹äºŒï¼š...",
        "timeline": [
            {"time": "6å°æ—¶å‰", "event": "äº‹ä»¶é¦–æ¬¡æ›å…‰ï¼Œå…³æ³¨åº¦ä¸Šå‡"},
            {"time": "2å°æ—¶å‰", "event": "ç›¸å…³æ–¹ä½œå‡ºå›åº”ï¼Œå¼•å‘è®¨è®º"},
            {"time": "30åˆ†é’Ÿå‰", "event": "çƒ­åº¦æŒç»­å‘é…µï¼Œå¤šæ–¹è§‚ç‚¹åšå¼ˆ"}
        ],
        "suggestion": "å»ºè®®ä»äº‰è®®ç‚¹åˆ‡å…¥è¿›è¡Œæ·±åº¦åˆ†æã€‚"
    }

def generate_event_pulse(title, content=""):
    """
    ç”Ÿæˆäº‹ä»¶è„‰ç»œã€äº‰è®®ç‚¹ã€æ—¶é—´çº¿å’Œå»ºè®®
    """
    if not client: return _get_mock_pulse(title)
    
    print(f"ğŸ“ˆ AI è„‰ç»œåˆ†æ: {title}")
    
    full_text = f"æ ‡é¢˜ï¼š{title}\nå†…å®¹æ‘˜è¦ï¼š{content[:1000]}"
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±è°ƒæŸ¥è®°è€…ã€‚è¯·å¯¹ç»™å®šçš„çƒ­ç‚¹äº‹ä»¶æ¢³ç†å‡ºæ¸…æ™°çš„è„‰ç»œã€‚
    
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    {
        "facts": "æ ¸å¿ƒäº‹å®ç®€è¿°ï¼ˆ50å­—å†…ï¼‰",
        "controversy": "åˆ—å‡º1-2ä¸ªæ ¸å¿ƒäº‰è®®ç‚¹æˆ–ç–‘é—®ç‚¹",
        "timeline": [
            {"time": "æ¨æµ‹æ—¶é—´ç‚¹ (å¦‚'2å°æ—¶å‰'æˆ–å…·ä½“æ—¥æœŸ)", "event": "å…³é”®èŠ‚ç‚¹äº‹ä»¶æè¿°"},
            {"time": "...", "event": "..."}
        ],
        "suggestion": "ä¸€å¥è¯åˆ›ä½œåˆ‡å…¥å»ºè®®"
    }
    
    è¦æ±‚ï¼š
    1. timeline æ•°ç»„åŒ…å« 3 ä¸ªå…³é”®èŠ‚ç‚¹ã€‚
    2. åŸºäºå¸¸è¯†æ¨ç†æˆ–å†…å®¹è¿›è¡Œåˆç†çš„å› æœæ¨æ¼”ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": full_text}
            ],
            stream=False
        )
        
        raw = response.choices[0].message.content
        print(f"ğŸ” [è„‰ç»œ-åŸå§‹è¿”å›]: {raw[:100]}...")
        clean = extract_json(raw)
        data = json.loads(clean)
        
        # Validation
        if "facts" not in data or "timeline" not in data:
            return _get_mock_pulse(title)
            
        return data
        
    except Exception as e:
        print(f"âŒ è„‰ç»œåˆ†æå¤±è´¥: {e}")
        return _get_mock_pulse(title)


# === 6. çƒ­è¯æå– (Keyword Extraction) ===
def extract_keywords_from_content(content: str, max_keywords: int = 8):
    """
    ä»èˆ†æƒ…å†…å®¹ä¸­æå–æ ¸å¿ƒçƒ­è¯åŠAIè§‚ç‚¹
    """
    if not client:
        # æ— AIæ—¶ä½¿ç”¨jiebaåˆ†è¯
        import jieba
        from collections import Counter
        words = [w for w in jieba.cut(content) if len(w) >= 2]
        word_counts = Counter(words).most_common(max_keywords)
        return [
            {"keyword": word, "opinion": f"å‡ºç°{count}æ¬¡", "count": count}
            for word, count in word_counts
        ]
    
    try:
        prompt = f"""åˆ†æä»¥ä¸‹èˆ†æƒ…å†…å®¹ï¼Œæå–6-8ä¸ªæ ¸å¿ƒçƒ­è¯ï¼Œå¹¶ä¸ºæ¯ä¸ªçƒ­è¯ç”Ÿæˆç®€çŸ­çš„AIè§‚ç‚¹æ€»ç»“ã€‚

å†…å®¹:
{content[:3000]}

è¯·è¿”å›JSONæ ¼å¼:
{{
  "keywords": [
    {{"keyword": "å…³é”®è¯1", "opinion": "AIè§‚ç‚¹: ä¸€å¥è¯æ€»ç»“ç”¨æˆ·å¯¹è¯¥è¯çš„çœ‹æ³•"}},
    {{"keyword": "å…³é”®è¯2", "opinion": "AIè§‚ç‚¹: ä¸€å¥è¯æ€»ç»“"}}
  ]
}}

æ³¨æ„:
1. å…³é”®è¯åº”è¯¥æ˜¯å†…å®¹ä¸­è®¨è®ºæœ€é¢‘ç¹çš„è¯é¢˜
2. AIè§‚ç‚¹è¦ç®€æ´ï¼Œä¸è¶…è¿‡20ä¸ªå­—
3. æŒ‰é‡è¦æ€§æ’åºï¼Œæœ€é‡è¦çš„æ’åœ¨å‰é¢
"""
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯èˆ†æƒ…åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»å¤§é‡æ–‡æœ¬ä¸­æå–æ ¸å¿ƒè¯é¢˜å’Œå…¬ä¼—è§‚ç‚¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.3
        )
        
        raw = response.choices[0].message.content
        clean = extract_json(raw)
        data = json.loads(clean)
        
        return data.get("keywords", [])[:max_keywords]
        
    except Exception as e:
        print(f"âŒ çƒ­è¯æå–å¤±è´¥: {e}")
        # Fallback to jieba
        import jieba
        from collections import Counter
        words = [w for w in jieba.cut(content) if len(w) >= 2]
        word_counts = Counter(words).most_common(max_keywords)
        return [
            {"keyword": word, "opinion": f"å‡ºç°{count}æ¬¡", "count": count}
            for word, count in word_counts
        ]

# === 7. é€šç”¨æ–‡æœ¬ç”Ÿæˆ (Generic Text Generation) ===
def call_gemini_text(prompt, context=""):
    """
    é€šç”¨æ–‡æœ¬ç”Ÿæˆå‡½æ•° (Legacy name, uses current configured client)
    """
    if not client: return "Mock AI Response: Client not configured."
    
    full_prompt = f"{context}\n\n{prompt}" if context else prompt
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": full_prompt}
            ],
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ AI Call Failed: {e}")
        return f"AI Generation Failed: {e}"