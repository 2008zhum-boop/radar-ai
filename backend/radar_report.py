import sqlite3
import json
import time
import random

DB_FILE = "radar_data.db"

def safe_json_load(json_str):
    try:
        if not json_str: return {}
        return json.loads(json_str)
    except:
        return {}

def get_client_info(client_id):
    try:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("SELECT name, industry, competitors FROM client_config WHERE client_id=?", (client_id,))
        row = c.fetchone()
        conn.close()
        if row:
            comps = safe_json_load(row[2]) if row[2] else []
            return row[0], row[1], comps
        return None, None, []
    except:
        return "æœªçŸ¥å®¢æˆ·", "æœªçŸ¥è¡Œä¸š", []

def get_volume(client_name, start_time, end_time):
    try:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("SELECT count(*) FROM mentions WHERE (title LIKE ? OR content_text LIKE ?) AND publish_time BETWEEN ? AND ?", 
                  (f"%{client_name}%", f"%{client_name}%", start_time, end_time))
        count = c.fetchone()[0]
        conn.close()
        return count
    except:
        return 0

def generate_client_report(client_id, time_range_hours=24):
    """
    ç”Ÿæˆä¸­æ–‡èˆ†æƒ…æ—¥æŠ¥
    """
    try:
        # 1. è·å–å®¢æˆ·ä¿¡æ¯
        client_name, industry, competitors = get_client_info(client_id)
        if not client_name: 
            return {"error": "Client not found"}

        now = time.time()
        past_24h = now - (24 * 3600)
        past_48h = now - (48 * 3600)

        # 2. æŸ¥è¯¢æ•°æ®
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute('''SELECT source, title, sentiment_score, risk_level, match_detail, publish_time 
                     FROM mentions 
                     WHERE client_id=? AND publish_time > ? 
                     ORDER BY publish_time DESC''', (client_id, past_24h))
        mentions = c.fetchall()
        conn.close()

        total_count = len(mentions)
        
        # 3. è®¡ç®—æŒ‡æ ‡
        prev_count = get_volume(client_name, past_48h, past_24h)
        if prev_count == 0: prev_count = 1
        growth_rate = ((total_count - prev_count) / prev_count) * 100
        
        pos_count = 0
        neg_count = 0
        risk_high_count = 0
        risk_mid_count = 0
        
        for m in mentions:
            try:
                score = float(m[2]) if m[2] is not None else 0
                risk = int(m[3]) if m[3] is not None else 1
                if score > 0.1: pos_count += 1
                if score < -0.1: neg_count += 1
                if risk == 3: risk_high_count += 1
                if risk == 2: risk_mid_count += 1
            except: continue

        sentiment_score = 7.5
        if total_count > 0:
            sentiment_score = 5 + (pos_count / total_count * 5) - (neg_count / total_count * 5)
        sentiment_score = round(max(0, min(10, sentiment_score)), 1)
        
        composite_score = 90 - (risk_high_count * 10) - (risk_mid_count * 5) + (pos_count * 0.5)
        composite_score = int(max(0, min(100, composite_score)))
        
        comp_name = competitors[0] if competitors else "è¡Œä¸šå¹³å‡"
        share_pct = 50 

        # 4. æå–çƒ­ç‚¹äº‹ä»¶
        top_events = []
        if len(mentions) > 0:
            neg_rows = [m for m in mentions if (m[3] or 1) >= 2]
            if neg_rows:
                row = neg_rows[0]
                detail = safe_json_load(row[4])
                top_events.append({
                    "title": row[1][:20] + "..." if len(row[1])>20 else row[1],
                    "heat": random.randint(1000, 5000),
                    "sentiment": "ğŸ˜¨ è´Ÿé¢é£é™©",
                    "nodes": row[0] or "å…¨ç½‘",
                    "views": [detail.get('reason', 'å‘½ä¸­é£é™©è§„åˆ™')]
                })
            else:
                row = mentions[0]
                top_events.append({
                    "title": row[1][:20] + "...",
                    "heat": random.randint(500, 2000),
                    "sentiment": "ğŸ˜ å¹³ç¨³",
                    "nodes": row[0] or "å…¨ç½‘",
                    "views": ["æ—¥å¸¸å“ç‰ŒæåŠ"]
                })
        else:
             top_events.append({
                "title": "æš‚æ— é‡å¤§çƒ­ç‚¹", "heat": 0, "sentiment": "ğŸ˜ å¹³ç¨³", "nodes": "-", "views": []
            })

        status_level = "ğŸŸ¢ å®‰å…¨"
        if composite_score < 60: status_level = "ğŸ”´ è­¦å‘Š"
        elif composite_score < 80: status_level = "ğŸŸ¡ å…³æ³¨"

        # 5. è¿”å›ç»“æ„
        return {
            "cover": {
                "report_name": f"[{client_name}] å…¨ç½‘èˆ†æƒ…ç›‘æµ‹æ—¥æŠ¥",
                "time_range": f"{time.strftime('%m-%d %H:%M', time.localtime(past_24h))} è‡³ {time.strftime('%m-%d %H:%M', time.localtime(now))}",
                "gen_time": time.strftime('%Y/%m/%d %H:%M'),
                "score": composite_score,
                "status": status_level
            },
            "section_1": {
                "summary": f"ç›‘æµ‹å‘¨æœŸå†…ï¼Œ{client_name} å£°é‡ç¯æ¯”{'ä¸Šå‡' if growth_rate>0 else 'ä¸‹é™'} {abs(int(growth_rate))}%ã€‚",
                "sentiment_desc": f"æ•´ä½“å¾—åˆ† {sentiment_score}ï¼Œæƒ…ç»ª{'å¹³ç¨³' if sentiment_score>6 else 'éœ€å…³æ³¨'}ã€‚",
                "risk_desc": f"å…±ç›‘æµ‹åˆ° {risk_high_count} æ¡é«˜å±ä¿¡æ¯ï¼Œ{risk_mid_count} æ¡é£é™©æç¤ºã€‚",
                "conclusion": "å»ºè®®ä¿æŒå¸¸è§„ç›‘æµ‹ã€‚" if risk_high_count==0 else "å»ºè®®ç«‹å³å¤„ç†é«˜å±é£é™©ã€‚"
            },
            "section_2": {
                "total_vol": f"{total_count} æ¡",
                "growth": f"{'ğŸ”º' if growth_rate>0 else 'ğŸ”»'} {abs(int(growth_rate))}%",
                "health_score": str(sentiment_score),
                "health_change": "-",
                "main_platform": "å…¨ç½‘èšåˆ",
                "comp_name": comp_name,
                "comp_data": f"æœ¬å“ ({share_pct}%) vs {comp_name} ({100-share_pct}%)"
            },
            "section_3": top_events,
            "section_4": {
                "level": status_level,
                "keywords": ["æ³¢åŠ¨", "å…³æ³¨"],
                "sample": neg_rows[0][1] if 'neg_rows' in locals() and neg_rows else "æš‚æ— é£é™©æ ·æœ¬",
                "source_analysis": "æ•°æ®æ¥æºäºå…¨ç½‘å®æ—¶ç›‘æµ‹ã€‚"
            },
            "section_5": {
                "defense": "æš‚æ— ç´§æ€¥é˜²å¾¡å»ºè®®ã€‚" if risk_high_count==0 else "è¯·å°½å¿«æ ¸å®é£é™©å†…å®¹çœŸå®æ€§ã€‚",
                "offense": "å»ºè®®æŒ–æ˜ç”¨æˆ·å¥½è¯„ç‚¹è¿›è¡Œä¼ æ’­ã€‚",
                "prediction": "é¢„è®¡æ˜æ—¥çƒ­åº¦å°†è¶‹äºå¹³ç¨³ã€‚"
            }
        }
    except Exception as e:
        print(f"REPORT ERROR: {e}")
        return {"error": str(e)}