import sqlite3
import json
import time
import random
import re

DB_FILE = "radar_data.db"

# === 1. åˆå§‹åŒ–ç›‘æ§ä¸“ç”¨è¡¨ ===
def init_monitor_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    # å…³é”®è¯é…ç½®è¡¨
    # type: 1=æ ¸å¿ƒåœˆ(å“ç‰Œ/é«˜ç®¡), 2=ç«å“åœˆ, 3=è¡Œä¸šåœˆ
    # sensitive_words: è¯¥è¯å…³è”çš„æ•æ„Ÿè¯ï¼Œç”¨é€—å·åˆ†éš”
    c.execute('''CREATE TABLE IF NOT EXISTS monitor_keywords
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, 
                  word TEXT, 
                  type INTEGER, 
                  category TEXT,
                  sensitive_words TEXT)''')
                  
    # èˆ†æƒ…æ—¥å¿—è¡¨ (å­˜å‚¨æ¸…æ´—åçš„é«˜ä»·å€¼ä¿¡å·)
    # level: 3=çº¢(å±æœº), 2=é»„(é£é™©/çƒ­ç‚¹), 1=ç»¿(æœºä¼š)
    c.execute('''CREATE TABLE IF NOT EXISTS monitor_logs
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  source TEXT,
                  title TEXT,
                  url TEXT,
                  publish_time REAL,
                  sentiment_score REAL,
                  source_weight INTEGER,
                  level INTEGER,
                  tags TEXT,
                  summary TEXT)''')
                  
    # é¢„ç½®ä¸€äº›åˆå§‹å…³é”®è¯ (Demoç”¨)
    c.execute("SELECT count(*) FROM monitor_keywords")
    if c.fetchone()[0] == 0:
        presets = [
            ("æ˜Ÿäº‘ç§‘æŠ€", 1, "å“ç‰Œ", "çˆ†ç‚¸,èµ·è¯‰,ç»´æƒ,å€’é—­,è£å‘˜"),
            ("é›·å†›", 1, "é«˜ç®¡", "ç¦»èŒ,å¥—ç°,è°£è¨€"),
            ("ç‰¹æ–¯æ‹‰", 2, "ç«å“", "åˆ¹è½¦å¤±çµ,é™ä»·,ç»´æƒ"),
            ("äººå·¥æ™ºèƒ½", 3, "è¡Œä¸š", "ç›‘ç®¡,æ³•æ¡ˆ,ç¦ä»¤")
        ]
        c.executemany("INSERT INTO monitor_keywords (word, type, category, sensitive_words) VALUES (?,?,?,?)", presets)
        conn.commit()
        
    conn.commit()
    conn.close()

init_monitor_db()

# === 2. åª’ä½“æºåˆ†çº§æƒé‡ (Source Weighting) ===
def get_source_weight(source_name):
    # Sçº§ (æƒé‡ 100)
    if source_name in ["å¾®åšçƒ­æœ", "å¤®è§†æ–°é—»", "äººæ°‘æ—¥æŠ¥"]:
        return 100
    # Açº§ (æƒé‡ 80)
    elif source_name in ["36æ°ª", "è™å—…", "é’›åª’ä½“", "å¤´æ¡å·", "è´¢è”ç¤¾"]:
        return 80
    # Bçº§ (æƒé‡ 50)
    elif source_name in ["ç™¾åº¦é£äº‘æ¦œ", "å¾®ä¿¡å…¬ä¼—å·"]:
        return 50
    # Cçº§
    return 30

# === 3. æƒ…æ„Ÿä¸æ•æ„Ÿè¯åˆ†æ (NLP Analysis) ===
def analyze_content(text, keyword_config):
    """
    åˆ†ææ–‡æœ¬ï¼Œè¿”å›ï¼šæƒ…æ„Ÿåˆ†æ•°(-1åˆ°1), å‘½ä¸­çš„æ•æ„Ÿè¯, æ˜¯å¦å‘½ä¸­å…³é”®è¯
    """
    # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«ç›‘æ§å…³é”®è¯
    target_word = keyword_config['word']
    if target_word not in text:
        return None # æ²¡å‘½ä¸­å…³é”®è¯ï¼Œç›´æ¥è¿‡æ»¤ï¼Œè§†ä¸ºå™ªéŸ³

    # 2. æ£€æŸ¥æ•æ„Ÿè¯ (è´Ÿé¢åˆ¤å®š)
    sensitive_list = keyword_config['sensitive_words'].split(',') if keyword_config['sensitive_words'] else []
    hit_sensitive = [w for w in sensitive_list if w and w in text]
    
    # 3. ç®€å•çš„æƒ…æ„Ÿæ‰“åˆ† (æ¨¡æ‹Ÿ)
    # å®é™…é¡¹ç›®ä¸­åº”è°ƒç”¨ NLP æ¨¡å‹
    score = 0.5 # é»˜è®¤ä¸­æ€§
    
    negative_words = ["å¤±æœ›", "åƒåœ¾", "ç»´æƒ", "é»‘å±", "å¡é¡¿", "éª—å­", "çˆ†ç‚¸", "æš´è·Œ"]
    positive_words = ["æƒŠå–œ", "é¥é¥é¢†å…ˆ", "ç‰›é€¼", "åˆ©å¥½", "å¤§æ¶¨", "çªç ´", "é¦–å‘"]
    
    # ç²—ç³™çš„è¯åº“åŒ¹é…
    for w in negative_words:
        if w in text: score -= 0.2
    for w in hit_sensitive:
        score -= 0.4 # å‘½ä¸­è‡ªå®šä¹‰æ•æ„Ÿè¯æ‰£åˆ†æ›´é‡
        
    for w in positive_words:
        if w in text: score += 0.2
        
    # é™åˆ¶èŒƒå›´
    score = max(-1, min(1, score))
    
    return {
        "score": score,
        "hit_sensitive": hit_sensitive,
        "matched_keyword": target_word
    }

# === 4. é¢„è­¦ç­‰çº§åˆ¤å®šé€»è¾‘ (The Alert System) ===
def determine_alert_level(sentiment_score, source_weight, hit_sensitive):
    # ğŸ”´ çº¢è‰²è­¦æŠ¥ (å±æœº)ï¼šæƒé‡é«˜ + æåº¦è´Ÿé¢ æˆ– å‘½ä¸­æ•æ„Ÿè¯
    if (sentiment_score < -0.3 and source_weight >= 80) or len(hit_sensitive) > 0:
        return 3 
    
    # ğŸŸ¡ é»„è‰²è­¦æŠ¥ (é£é™©/çƒ­ç‚¹)ï¼šæƒé‡é«˜ + å…³é”®è¯æåŠ (å¯èƒ½æ˜¯çƒ­ç‚¹ï¼Œä¹Ÿå¯èƒ½æ˜¯è½»å¾®è´Ÿé¢)
    if source_weight >= 80 or (sentiment_score < 0):
        return 2
        
    # ğŸŸ¢ ç»¿è‰²ä¿¡å· (æœºä¼š)ï¼šæ­£é¢æƒ…ç»ª æˆ– æ™®é€šæåŠ
    return 1

# === 5. æ ¸å¿ƒå¤„ç†ç®¡é“ (Pipeline) ===
def process_monitor_data(raw_items):
    """
    æ¥æ”¶çˆ¬è™«æŠ“å›æ¥çš„åŸå§‹æ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—ã€åŒ¹é…ã€å…¥åº“
    """
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    # è·å–æ‰€æœ‰é…ç½®çš„å…³é”®è¯
    c.execute("SELECT * FROM monitor_keywords")
    # è½¬ä¸ºå­—å…¸åˆ—è¡¨
    keywords = [{"word": row[1], "type": row[2], "category": row[3], "sensitive_words": row[4]} for row in c.fetchall()]
    
    processed_count = 0
    alerts = []

    for item in raw_items:
        text = item['title'] + (item.get('summary') or "")
        source = item['source']
        weight = get_source_weight(source)
        
        # éå†å…³é”®è¯çŸ©é˜µè¿›è¡ŒåŒ¹é…
        for kw in keywords:
            analysis = analyze_content(text, kw)
            
            if analysis: # å‘½ä¸­äº†ï¼
                level = determine_alert_level(analysis['score'], weight, analysis['hit_sensitive'])
                
                # å…¥åº“
                c.execute('''INSERT INTO monitor_logs 
                             (source, title, url, publish_time, sentiment_score, source_weight, level, tags, summary)
                             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                          (source, item['title'], item['url'], time.time(), 
                           analysis['score'], weight, level, 
                           f"{kw['category']}-{kw['word']}", 
                           item.get('summary', '')))
                
                processed_count += 1
                
                # å¦‚æœæ˜¯çº¢è‰²æˆ–é»„è‰²ï¼ŒåŠ å…¥å®æ—¶å‘Šè­¦åˆ—è¡¨è¿”å›
                if level >= 2:
                    alerts.append({
                        "level": level,
                        "title": item['title'],
                        "reason": f"å‘½ä¸­[{kw['word']}]" + (f"+æ•æ„Ÿè¯[{','.join(analysis['hit_sensitive'])}]" if analysis['hit_sensitive'] else "")
                    })
                
                # ä¸€æ¡æ–°é—»åªåŒ¹é…ä¸€æ¬¡ä¸»å…³é”®è¯å³å¯ï¼Œé¿å…é‡å¤å…¥åº“
                break
    
    conn.commit()
    conn.close()
    return {"processed": processed_count, "alerts": alerts}

# === API æ¥å£æ”¯æŒ ===
def get_monitor_stats():
    """è·å–çœ‹æ¿ç»Ÿè®¡æ•°æ®"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    # ä»Šæ—¥å£°é‡
    c.execute("SELECT count(*) FROM monitor_logs WHERE publish_time > ?", (time.time() - 86400,))
    today_count = c.fetchone()[0]
    
    # é£é™©æŒ‡æ•° (çº¢è‰²è­¦æŠ¥æ•°é‡)
    c.execute("SELECT count(*) FROM monitor_logs WHERE level=3 AND publish_time > ?", (time.time() - 86400,))
    risk_count = c.fetchone()[0]
    
    # æœ€è¿‘çš„ç›‘æ§æ—¥å¿—
    logs = []
    c.execute("SELECT * FROM monitor_logs ORDER BY id DESC LIMIT 20")
    for row in c.fetchall():
        logs.append({
            "id": row[0],
            "source": row[1],
            "title": row[2],
            "url": row[3],
            "time": time.strftime("%H:%M", time.localtime(row[4])),
            "score": row[5],
            "weight": row[6],
            "level": row[7], # 3çº¢ 2é»„ 1ç»¿
            "tags": row[8],
            "summary": row[9]
        })
        
    conn.close()
    return {
        "today_count": today_count,
        "risk_count": risk_count,
        "logs": logs
    }

def get_config_keywords():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT * FROM monitor_keywords")
    data = [{"id": r[0], "word": r[1], "type": r[2], "category": r[3], "sensitive": r[4]} for r in c.fetchall()]
    conn.close()
    return data

def add_config_keyword(word, type_id, category, sensitive):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT INTO monitor_keywords (word, type, category, sensitive_words) VALUES (?,?,?,?)", 
              (word, type_id, category, sensitive))
    conn.commit()
    conn.close()