import os
import json
import re
import time
import requests
from typing import Optional

# ================= ğŸš€ æ ¸å¿ƒé…ç½® =================

# 1. SiliconFlow Key
SILICON_KEY = "sk-xhlggbibvssprqgoadkdpxdnsbpzdeqfpkcrnhhnuohowrpd"

# 2. æ¨¡å‹é€‰æ‹©
SILICON_MODEL_MAIN = "Qwen/Qwen2.5-72B-Instruct" 
SILICON_MODEL_BACKUP = "deepseek-ai/DeepSeek-V3"

# 3. Google é…ç½®
GEMINI_API_KEY = "AIzaSyCIrIYeRTujYGAina6k67YKqldr1PiOx7Y"
GEMINI_MODEL = "gemini-2.0-flash"

# 4. ä»£ç†åœ°å€
PROXY_URL = "socks5h://127.0.0.1:9091"

# =============================================

def get_proxies(force_proxy=False):
    if force_proxy:
        return { "http": PROXY_URL, "https": PROXY_URL }
    else:
        return { "http": None, "https": None }

def call_silicon_raw(prompt, model_name):
    if not SILICON_KEY: return None
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = { "Authorization": f"Bearer {SILICON_KEY}", "Content-Type": "application/json" }
    data = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 1024
    }
    try:
        resp = requests.post(url, headers=headers, json=data, timeout=20, proxies=get_proxies(False))
        if resp.status_code == 200:
            return resp.json()['choices'][0]['message']['content']
        elif resp.status_code == 402:
            print(f"âš ï¸ {model_name} ä½™é¢ä¸è¶³ (402)ï¼Œè·³è¿‡...")
        else:
            print(f"âš ï¸ SiliconFlow ({model_name}) Error: {resp.text[:100]}")
    except Exception as e: 
        print(f"âš ï¸ SF Network Error: {e}")
    return None

def call_gemini(prompt):
    if not GEMINI_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    data = { "contents": [{ "parts": [{"text": prompt}] }] }
    try:
        for i in range(2):
            if i > 0: time.sleep(1)
            resp = requests.post(url, headers=headers, json=data, timeout=30, proxies=get_proxies(True))
            if resp.status_code == 200:
                res = resp.json()
                if "candidates" in res: return res["candidates"][0]["content"]["parts"][0]["text"].strip()
    except: pass
    return None

def call_ai(prompt):
    res = call_silicon_raw(prompt, SILICON_MODEL_MAIN)
    if res: return res
    print(f"âš ï¸ ä¸»æ¨¡å‹å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨...")
    res = call_silicon_raw(prompt, SILICON_MODEL_BACKUP)
    if res: return res
    print("âš ï¸ SiliconFlow å…¨çº¿å¤±è´¥ï¼Œåˆ‡æ¢ Google Gemini...")
    return call_gemini(prompt)

def _safe_json(text: Optional[str]):
    if not text: return None
    try:
        text = re.sub(r"^```json\s*", "", text)
        text = re.sub(r"^```\s*", "", text)
        text = re.sub(r"\s*```$", "", text)
        match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
        if match: text = match.group(0)
        return json.loads(text)
    except: return None

# ================= ä¸šåŠ¡é€»è¾‘ =================

def generate_news_summary(title, content=""):
    full_text = f"æ ‡é¢˜ï¼š{title}\nå†…å®¹ç®€è¿°ï¼š{content[:1000]}"
    
    # ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šå¢åŠ  emotions å­—æ®µï¼Œè¦æ±‚è¿”å› 5 ç§å…·ä½“æƒ…ç»ª
    prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±èˆ†æƒ…åˆ†æå¸ˆã€‚è¯·åˆ†æè¿™æ¡æ–°é—»çš„é€‰é¢˜ä»·å€¼ï¼Œå¹¶ç²¾å‡†åˆ¤æ–­å…¶è•´å«çš„æƒ…ç»ªæˆåˆ†ã€‚
    
    è¯·è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š
    {{
        "fact": "100å­—ä»¥å†…çš„æ·±åº¦æ‘˜è¦",
        "score": 0-100 (é€‰é¢˜ä»·å€¼),
        "trend": "ä¸Šå‡/å¹³ç¨³/ä¸‹é™",
        "reason": "æ¨èç†ç”±",
        "category": "ä»ä»¥ä¸‹é€‰æ‹©: [ç»¼åˆ, å¤§æ¨¡å‹, ç§‘æŠ€, è´¢ç», é‡‘è, æ±½è½¦, å¤§å¥åº·, æ–°æ¶ˆè´¹, åˆ›æŠ•, å‡ºæµ·, å¤§å…¬å¸, å›½é™…]",
        "tags": ["æ ‡ç­¾1"],
        "sentiment": {{ "positive": 20, "neutral": 60, "negative": 20 }},
        "emotions": {{
            "anxiety": 10,   // ç„¦è™‘ (å¦‚è£å‘˜ã€åˆ¶è£ã€äºæŸ)
            "anger": 5,      // æ„¤æ€’ (å¦‚ä¸‘é—»ã€ä¾µæƒã€ä¸å…¬)
            "sadness": 5,    // æ‚²ä¼¤ (å¦‚é€ä¸–ã€å¤±è´¥ã€ç¾éš¾)
            "excitement": 10,// å…´å¥‹ (å¦‚çªç ´ã€æ–°é«˜ã€å‘å¸ƒ)
            "sarcasm": 0     // å˜²è®½ (å¦‚åƒç“œã€åè½¬ã€æ‰“è„¸)
        }}
    }}
    
    æ³¨æ„ï¼š
    1. sentiment ä¸‰é¡¹ä¹‹å’Œå¿…é¡»ä¸º 100ã€‚
    2. emotions çš„äº”é¡¹æ•°å€¼ä»£è¡¨å¼ºåº¦(0-100)ï¼Œä¸éœ€è¦åŠ èµ·æ¥ç­‰äº100ï¼Œä½†è¦ç¬¦åˆé€»è¾‘ã€‚è‹¥æ–°é—»å¾ˆå¹³æ·¡ï¼Œæ‰€æœ‰æƒ…ç»ªå€¼éƒ½åº”è¾ƒä½ã€‚
    
    æ–°é—»ï¼š
    {full_text}
    """
    
    res = call_ai(prompt)
    data = _safe_json(res)
    
    if data: return data
    
    return {}

# å…¼å®¹æ¥å£
def call_openrouter(prompt): return call_ai(prompt)
def analyze_topic_deeply(topic): return _safe_json(call_ai(f"åˆ†æè¯é¢˜ï¼š{topic}ï¼Œè¿”å›json")) or {}
def generate_full_outline(topic, angle): return _safe_json(call_ai(f"å†™å¤§çº²ï¼š{topic}ï¼Œè§’åº¦{angle}ï¼Œè¿”å›json")) or []
def generate_smart_outline(title, angle, context=""): return _safe_json(call_ai(f"è¯¦ç»†å¤§çº²ï¼š{title}ï¼Œè¿”å›json")) or {}
def generate_full_article(title, outline, context=""): return call_ai(f"å†™æ–‡ç« ï¼š{title}ï¼Œå¤§çº²{outline}") or ""